{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231ac0f8",
   "metadata": {},
   "source": [
    "# XGBoost Regressor Hyperparameter Optimization\n",
    "\n",
    "This notebook demonstrates how to optimize XGBoost regressor hyperparameters using the following:\n",
    "- TimeSeriesSplit with 5 folds for cross-validation\n",
    "- Optuna for hyperparameter optimization\n",
    "- The tabularaml library's cv.py function for evaluation\n",
    "- Optimization metric: exp(-RMSE/100)\n",
    "\n",
    "The goal is to create a submission file with columns 'id' and 'pollution_value' containing our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6917190",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb13348-2c12-467f-82a7-c19f4506cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q numpy pandas optuna \"xgboost>=1.7.0\" scikit-learn category_encoders matplotlib seaborn cloudpickle optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb77121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c3538",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data\n",
    "\n",
    "Let's load the training and test datasets. We'll assume the files are in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b464f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re\n",
    "from tabularaml.generate.features import FeatureGenerator\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_format = pd.read_csv('submission_example.csv')\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "# Assume a dummy year since it's not provided\n",
    "year = 2023\n",
    "# Construct datetime from day_of_year and hour\n",
    "train_df['datetime'] = pd.to_datetime(train_df['day_of_year'], format='%j', errors='coerce') \\\n",
    "                       + pd.to_timedelta(train_df['hour'], unit='h')\n",
    "train_df['datetime'] = train_df['datetime'].apply(\n",
    "    lambda dt: dt.replace(year=year) if pd.notnull(dt) else dt\n",
    ")\n",
    "# Sort by datetime column\n",
    "train_df = train_df.sort_values(by='datetime')\n",
    "# Drop the temporary datetime column\n",
    "train_df = train_df.drop(columns='datetime')\n",
    "# Reset the index\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "X_train = train_df.drop([\n",
    "    \"id\",\n",
    "    \"pollution_value\"], axis=1).copy()\n",
    "X_train_before = X_train.copy()\n",
    "X_test = test_df.copy()\n",
    "\n",
    "DIR = \"model_redone\"\n",
    "\n",
    "# if os.path.isdir(DIR):\n",
    "#     for f in sorted(\n",
    "#         (f for f in os.listdir(DIR) if re.match(r\"feature_generator_\\d+\\.pkl\", f)),\n",
    "#         key=lambda x: int(re.search(r\"\\d+\", x).group())\n",
    "#     ):\n",
    "#         try:\n",
    "#             gen = FeatureGenerator.load(f\"{DIR}/{f}\")\n",
    "#             X_train = gen.fit_transform(X_train)\n",
    "#             X_test = gen.transform(X_test)\n",
    "#             print(f\"Loaded and transformed with {f} successfully.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Skipped {f}: {e}\")\n",
    "\n",
    "y_train = train_df[\"pollution_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9477c",
   "metadata": {},
   "source": [
    "## 3. Prepare Features and Target\n",
    "\n",
    "Let's prepare the features and target variable for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf5b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (7649, 6)\n",
      "Target shape: (7649,)\n",
      "Test features shape: (2739, 7)\n",
      "\n",
      "Missing values in training features:\n",
      "latitude       13\n",
      "longitude      13\n",
      "day_of_year     0\n",
      "day_of_week     0\n",
      "hour            0\n",
      "month           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in target:\n",
      "0\n",
      "\n",
      "Missing values in test features:\n",
      "id             0\n",
      "latitude       0\n",
      "longitude      0\n",
      "day_of_year    0\n",
      "day_of_week    0\n",
      "hour           0\n",
      "month          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_ids = test_df['id'].copy() \n",
    "# test_ids = test_data['id']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training features:\")\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in target:\")\n",
    "print(y_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test features:\")\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36975572",
   "metadata": {},
   "source": [
    "## 4. Set Up TimeSeriesSplit Cross-Validation\n",
    "\n",
    "For time series data, we need to use a time-based validation approach. We'll use `TimeSeriesSplit` from scikit-learn with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2557f7-5449-4c8c-ae73-03d450758f5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import BaseCrossValidator\n",
    "import numpy as np\n",
    "\n",
    "class FixedWindowTimeSeriesSplit(BaseCrossValidator):\n",
    "    \"\"\"\n",
    "    Custom time-series cross-validator with fixed-size test windows.\n",
    "    Ensures every fold has meaningful training data and proper temporal ordering.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int\n",
    "        Number of folds. Must be at least 1.\n",
    "    test_size : int\n",
    "        Number of samples in each test fold.\n",
    "    gap : int, default=0\n",
    "        Number of samples to exclude between train and test sets.\n",
    "    min_train_size : int, default=None\n",
    "        Minimum number of training samples required. If None, defaults to test_size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_splits=5, test_size=2700, gap=0, min_train_size=None):\n",
    "        if n_splits < 1:\n",
    "            raise ValueError(\"n_splits must be at least 1.\")\n",
    "        if test_size < 1:\n",
    "            raise ValueError(\"test_size must be at least 1.\")\n",
    "        if gap < 0:\n",
    "            raise ValueError(\"gap must be non-negative.\")\n",
    "        \n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.gap = gap\n",
    "        self.min_train_size = min_train_size or test_size\n",
    "        \n",
    "        if self.min_train_size < 1:\n",
    "            raise ValueError(\"min_train_size must be at least 1.\")\n",
    "    \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        \n",
    "        # Check if we have enough data for at least one split\n",
    "        min_required = self.min_train_size + self.gap + self.test_size\n",
    "        if min_required > n_samples:\n",
    "            raise ValueError(\n",
    "                f\"Not enough samples. Need at least {min_required} samples \"\n",
    "                f\"(min_train_size={self.min_train_size} + gap={self.gap} + test_size={self.test_size}), \"\n",
    "                f\"but got {n_samples}.\"\n",
    "            )\n",
    "        \n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        if self.n_splits == 1:\n",
    "            # Single window: place test at the end, ensure minimum training size\n",
    "            test_end = n_samples\n",
    "            test_start = test_end - self.test_size\n",
    "            train_end = test_start - self.gap\n",
    "            \n",
    "            # Ensure we have minimum training size\n",
    "            if train_end < self.min_train_size:\n",
    "                train_end = self.min_train_size\n",
    "                test_start = train_end + self.gap\n",
    "                test_end = test_start + self.test_size\n",
    "                \n",
    "                # Check if this fits within our data\n",
    "                if test_end > n_samples:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot fit single split with constraints. \"\n",
    "                        f\"Need {self.min_train_size + self.gap + self.test_size} samples, got {n_samples}.\"\n",
    "                    )\n",
    "            \n",
    "            train_idx = indices[:train_end]\n",
    "            test_idx = indices[test_start:test_end]\n",
    "            yield train_idx, test_idx\n",
    "            return\n",
    "        \n",
    "        # For multiple splits, distribute test windows\n",
    "        # Last test window ends at n_samples, work backwards\n",
    "        test_windows = []\n",
    "        \n",
    "        # Calculate positions for test windows\n",
    "        # We want to distribute them evenly in the available space\n",
    "        latest_test_end = n_samples\n",
    "        earliest_test_start = self.min_train_size + self.gap\n",
    "        \n",
    "        # Available space for test window starts\n",
    "        available_space = latest_test_end - self.test_size - earliest_test_start\n",
    "        \n",
    "        if available_space < 0:\n",
    "            raise ValueError(\n",
    "                \"Cannot create requested splits. Try reducing n_splits, test_size, or min_train_size.\"\n",
    "            )\n",
    "        \n",
    "        # Calculate step size between test windows\n",
    "        if self.n_splits == 1:\n",
    "            step = 0\n",
    "        else:\n",
    "            step = available_space / (self.n_splits - 1)\n",
    "        \n",
    "        # Generate test windows from last to first\n",
    "        for i in range(self.n_splits):\n",
    "            # Calculate test window position\n",
    "            test_start = int(earliest_test_start + i * step)\n",
    "            test_end = test_start + self.test_size\n",
    "            \n",
    "            # Ensure test window doesn't exceed data bounds\n",
    "            if test_end > n_samples:\n",
    "                test_end = n_samples\n",
    "                test_start = test_end - self.test_size\n",
    "            \n",
    "            # Calculate training end (before gap)\n",
    "            train_end = test_start - self.gap\n",
    "            \n",
    "            # Ensure minimum training size\n",
    "            if train_end < self.min_train_size:\n",
    "                raise ValueError(\n",
    "                    f\"Split {i+1} would have insufficient training data. \"\n",
    "                    f\"Try reducing n_splits or min_train_size.\"\n",
    "                )\n",
    "            \n",
    "            train_idx = indices[:train_end]\n",
    "            test_idx = indices[test_start:test_end]\n",
    "            \n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abea518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tss = FixedWindowTimeSeriesSplit(n_splits=5, test_size=2700)\n",
    "\n",
    "\n",
    "# Visualize the TimeSeriesSplit\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tss.split(X_train)):\n",
    "    plt.scatter(test_index, [i+0.5]*len(test_index), \n",
    "                c='red', s=10, label='Testing set' if i == 0 else \"\")\n",
    "    plt.scatter(train_index, [i+0.5]*len(train_index), \n",
    "                c='blue', s=10, label='Training set' if i == 0 else \"\")\n",
    "\n",
    "plt.yticks(np.arange(5) + 0.5, [f'Fold {i+1}' for i in range(5)])\n",
    "plt.title('TimeSeriesSplit with 5 folds')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fff938-8892-4f9f-ae0d-59bcf55bbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Fold 1\n",
      "  - Train size: 2700, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1613\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "5     162\n",
      "6     208\n",
      "7     372\n",
      "8    1958\n",
      "\n",
      "🔁 Fold 2\n",
      "  - Train size: 3262, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      192\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "7     180\n",
      "8    1961\n",
      "9     559\n",
      "\n",
      "🔁 Fold 3\n",
      "  - Train size: 3824, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      372\n",
      "8      382\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "8    1579\n",
      "9    1121\n",
      "\n",
      "🔁 Fold 4\n",
      "  - Train size: 4386, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      372\n",
      "8      944\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "8     1017\n",
      "9     1273\n",
      "10     410\n",
      "\n",
      "🔁 Fold 5\n",
      "  - Train size: 4949, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      372\n",
      "8     1507\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "8      454\n",
      "9     1273\n",
      "10     555\n",
      "11     219\n",
      "12     199\n"
     ]
    }
   ],
   "source": [
    "for i, (train_idx, val_idx) in enumerate(tss.split(X_train, y_train), 1):\n",
    "    train_months = X_train.iloc[train_idx][\"month\"].value_counts().sort_index()\n",
    "    val_months = X_train.iloc[val_idx][\"month\"].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\n🔁 Fold {i}\")\n",
    "    print(f\"  - Train size: {len(train_idx)}, Val size: {len(val_idx)}\")\n",
    "    print(\"  - Train months:\\n\", train_months.to_string())\n",
    "    print(\"  - Val months:\\n\", val_months.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ff60d",
   "metadata": {},
   "source": [
    "## 5. Define Optuna Objective Function for XGBoost GBRegressor\n",
    "\n",
    "Now, we'll define the Optuna objective function to optimize XGBoost hyperparameters using our custom metric and TimeSeriesSplit cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71ad2fa-3b07-4597-b3f4-556f5e8ef81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from spatio_temporal import AdvancedSpatioTemporalFeatures, SpatioTemporalDistributionAnalyzer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to optimize XGBoost hyperparameters with AdvancedSpatioTemporalFeatures\n",
    "    \"\"\"\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 2000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.5, 20),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.4, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 0, 1000),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 512),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'enable_categorical': True,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1  # Use all CPU cores\n",
    "    }\n",
    "    \n",
    "    # AdvancedSpatioTemporalFeatures hyperparameters\n",
    "    n_spatial_clusters = trial.suggest_int('n_spatial_clusters', 15, 35)\n",
    "    n_temporal_clusters = trial.suggest_int('n_temporal_clusters', 8, 18)\n",
    "    \n",
    "    # Use predefined splitter for cross-validation\n",
    "    folds = tss\n",
    "    \n",
    "    # Calculate test distribution stats using the analyzer from spatio_temporal.py\n",
    "    temporal_stats = get_test_distribution_stats()\n",
    "    \n",
    "    # Use existing X_train and y_train\n",
    "    X_base = X_train.copy()\n",
    "    y = y_train.copy()\n",
    "    \n",
    "    # Apply log transformation to the target variable\n",
    "    y = np.log1p(y)\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_base, y)):\n",
    "        # Split base features\n",
    "        X_train_fold = X_base.iloc[train_idx].copy()\n",
    "        X_valid_fold = X_base.iloc[valid_idx].copy()\n",
    "        X_test_fold = X_test.copy()\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        y_valid_fold = y.iloc[valid_idx]\n",
    "\n",
    "        # Apply AdvancedSpatioTemporalFeatures with optimized parameters\n",
    "        fe = AdvancedSpatioTemporalFeatures(\n",
    "            row_only=False,  # Use clustering features inside CV\n",
    "            n_spatial_clusters=n_spatial_clusters,\n",
    "            n_temporal_clusters=n_temporal_clusters,\n",
    "            january_bridge_features=True,  # Use January focus per user request\n",
    "            test_distribution=temporal_stats,\n",
    "            use_distribution_matching=True  # Use distribution matching features\n",
    "        )\n",
    "        \n",
    "        # Apply feature engineering\n",
    "        X_train_enhanced = fe.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_valid_enhanced = fe.transform(X_valid_fold)\n",
    "        X_test_enhanced = fe.transform(X_test_fold)  # Keep for consistency\n",
    "        \n",
    "        # Train model on this fold\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train_enhanced, y_train_fold)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred_fold = model.predict(X_valid_enhanced)\n",
    "        \n",
    "        # Inverse transform predictions and actual values to calculate RMSE on original scale\n",
    "        y_pred_orig_scale = np.expm1(y_pred_fold)\n",
    "        y_valid_orig_scale = np.expm1(y_valid_fold)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid_orig_scale, y_pred_orig_scale))\n",
    "        \n",
    "        # Convert to exponential score format\n",
    "        exp_score = np.exp(-rmse / 100)\n",
    "        fold_scores.append(exp_score)\n",
    "    \n",
    "    # Return the mean validation score to maximize\n",
    "    return np.mean(fold_scores)\n",
    "\n",
    "\n",
    "def get_test_distribution_stats():\n",
    "    \"\"\"Get test distribution stats using SpatioTemporalDistributionAnalyzer\"\"\"\n",
    "    # Create dummy DataFrames with required columns for the analyzer\n",
    "    train_df_for_analysis = train_df.copy()\n",
    "    test_df_for_analysis = test_df.copy()\n",
    "    \n",
    "    # Run the analyzer\n",
    "    analyzer = SpatioTemporalDistributionAnalyzer()\n",
    "    spatial_stats, temporal_stats = analyzer.analyze(train_df_for_analysis, test_df_for_analysis, verbose=False)\n",
    "    \n",
    "    return temporal_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b500b2a",
   "metadata": {},
   "source": [
    "## 6. Run Optuna Optimization\n",
    "\n",
    "Now we'll run the optimization process to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be1d84-5a88-4149-961e-6ba3fe5ba8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 03:44:26,268] A new study created in RDB with name: xgboost_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍  Running 500 trials …\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────── 4. Sampler & pruner ───────────────────────────────────\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "sampler = TPESampler(\n",
    "    multivariate=True,\n",
    "    group=True,\n",
    "    n_startup_trials=20,\n",
    "    constant_liar=True,   # set False if running strictly single-threaded\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "pruner = HyperbandPruner(\n",
    "    min_resource=1,       # first boosting round\n",
    "    max_resource=1000,    # must match the upper bound of n_estimators\n",
    "    reduction_factor=3,\n",
    ")\n",
    "\n",
    "# ──────────────────── 5. Create / resume study ──────────────────────────────\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"xgboost_optimization\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    storage=\"sqlite:///xgb_optuna.db\",  # makes the study persistent\n",
    "    load_if_exists=True,               # resume if the DB already exists\n",
    ")\n",
    "\n",
    "# ──────────────────── 6. Optimise ───────────────────────────────────────────\n",
    "N_TRIALS = 500\n",
    "print(f\"🔍  Running {N_TRIALS} trials …\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# ──────────────────── 7. Results ────────────────────────────────────────────\n",
    "best = study.best_trial\n",
    "print(\"\\n🎯  Best trial\")\n",
    "print(f\"    exp(-RMSE/100) : {best.value:.4f}\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"    {k:<18}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85aac9-30f4-4ea0-acb3-1f55c03d73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_trial\n",
    "print(\"\\n🎯  Best trial\")\n",
    "print(f\"    exp(-RMSE/100) : {best.value:.4f}\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"    {k:<18}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e82624-e589-4e83-b645-f74c87034bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimization process\n",
    "plt.figure(figsize=(10, 6))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "plt.title('Optimization History')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)\n",
    "plt.title('Hyperparameter Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c6b35-3e48-431b-96e9-55eca2c2c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import optuna\n",
    "\n",
    "# # Assume the following variables already exist from your setup before Optuna:\n",
    "# # X_train: pd.DataFrame with features, including the original 'month' column\n",
    "# # y_train: pd.Series with the target 'pollution_value'\n",
    "# # create_cyclical_features: The function you defined\n",
    "# # RANDOM_STATE: The integer seed you used\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 1. LOAD THE COMPLETED STUDY AND GET THE BEST PARAMETERS\n",
    "# # ---------------------------------------------------------------------------\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"🚀  Starting Final Sanity Check on the 'Golden' January Fold\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# try:\n",
    "#     # Load the study from the database\n",
    "#     study = optuna.load_study(\n",
    "#         study_name=\"xgboost_optimization\",\n",
    "#         storage=\"sqlite:///xgb_optuna.db\"\n",
    "#     )\n",
    "#     best_params = study.best_params.copy() # Use .copy() to avoid modifying the original\n",
    "#     print(\"✅ Successfully loaded best parameters from Optuna study.\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Could not load study due to: {e}. Please ensure the study exists.\")\n",
    "#     # In a real run, you might want to exit here or use default parameters\n",
    "#     # For this example, we'll stop if the study isn't found.\n",
    "#     exit()\n",
    "\n",
    "# # Separate the model hyperparameters from our custom preprocessing hyperparameter\n",
    "# n_clusters_best = best_params.pop('n_clusters')\n",
    "# xgb_best_params = best_params\n",
    "\n",
    "# # Add back the fixed XGBoost parameters needed for instantiation\n",
    "# xgb_best_params.update({\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'enable_categorical': True,\n",
    "#     'random_state': RANDOM_STATE,\n",
    "#     'n_jobs': -1\n",
    "# })\n",
    "\n",
    "# print(\"\\n📋 Best Hyperparameters for Final Model:\")\n",
    "# for k, v in xgb_best_params.items():\n",
    "#     print(f\"    {k:<18}: {v}\")\n",
    "# print(f\"    {'n_clusters':<18}: {n_clusters_best}\")\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 2. CREATE THE \"GOLDEN\" SPLIT FROM EXISTING X_train and y_train\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # Create boolean masks based on the 'month' column in the existing X_train\n",
    "# train_mask = X_train['month'] != 1\n",
    "# val_mask = X_train['month'] == 1\n",
    "\n",
    "# # Create the final training and validation sets using the masks\n",
    "# X_train_final = X_train.loc[train_mask].copy()\n",
    "# X_val_final = X_train.loc[val_mask].copy()\n",
    "\n",
    "# y_train_final = y_train.loc[train_mask].copy()\n",
    "# y_val_final = y_train.loc[val_mask].copy() # This is the true target for the golden fold\n",
    "\n",
    "# print(f\"\\nGolden Split created from existing X_train:\")\n",
    "# print(f\"  - Final Train size: {len(X_train_final)}\")\n",
    "# print(f\"  - Final Validation size: {len(X_val_final)}\")\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 3. APPLY THE IDENTICAL PREPROCESSING PIPELINE\n",
    "# # ---------------------------------------------------------------------------\n",
    "# print(\"\\n🔧 Applying preprocessing pipeline...\")\n",
    "\n",
    "# # a) Cyclical Features\n",
    "# # This function should drop the original time columns as it did in the objective\n",
    "# X_train_final = create_cyclical_features(X_train_final)\n",
    "# X_val_final = create_cyclical_features(X_val_final)\n",
    "\n",
    "# # b) K-Means Clustering Feature\n",
    "# if 'latitude' in X_train_final.columns and 'longitude' in X_train_final.columns:\n",
    "#     print(f\"  - Fitting KMeans with n_clusters={n_clusters_best}...\")\n",
    "#     kmeans = KMeans(n_clusters=n_clusters_best, random_state=RANDOM_STATE, n_init='auto')\n",
    "    \n",
    "#     # Impute NaNs temporarily just for clustering\n",
    "#     lat_mean = X_train_final['latitude'].mean()\n",
    "#     lon_mean = X_train_final['longitude'].mean()\n",
    "#     train_coords_temp = X_train_final[['latitude', 'longitude']].fillna({'latitude': lat_mean, 'longitude': lon_mean})\n",
    "#     valid_coords_temp = X_val_final[['latitude', 'longitude']].fillna({'latitude': lat_mean, 'longitude': lon_mean})\n",
    "    \n",
    "#     kmeans.fit(train_coords_temp)\n",
    "    \n",
    "#     X_train_final['cluster'] = kmeans.predict(train_coords_temp)\n",
    "#     X_val_final['cluster'] = kmeans.predict(valid_coords_temp)\n",
    "#     print(\"  - Cluster feature added.\")\n",
    "\n",
    "# # c) Log-transform the target for training\n",
    "# y_train_log = np.log1p(y_train_final)\n",
    "\n",
    "# # d) Align columns to ensure consistency\n",
    "# common_features = list(X_train_final.columns.intersection(X_val_final.columns))\n",
    "# X_train_final = X_train_final[common_features]\n",
    "# X_val_final = X_val_final[common_features]\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 4. TRAIN THE FINAL MODEL AND EVALUATE\n",
    "# # ---------------------------------------------------------------------------\n",
    "# print(\"\\n🧠 Training final model with best parameters...\")\n",
    "# final_model = xgb.XGBRegressor(**xgb_best_params)\n",
    "\n",
    "# final_model.fit(X_train_final, y_train_log)\n",
    "\n",
    "# print(\"📈 Predicting on the January validation set...\")\n",
    "# y_pred_log = final_model.predict(X_val_final)\n",
    "\n",
    "# # Inverse transform predictions to get them back to the original scale\n",
    "# y_pred_orig_scale = np.expm1(y_pred_log)\n",
    "\n",
    "# # Calculate the final, reliable RMSE on the original scale validation target\n",
    "# final_rmse = np.sqrt(mean_squared_error(y_val_final, y_pred_orig_scale))\n",
    "# final_exp_score = np.exp(-final_rmse / 100)\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"🏆 FINAL PERFORMANCE ESTIMATE 🏆\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"  RMSE on 'Golden' January Fold: {final_rmse:.4f}\")\n",
    "# print(f\"  Competition Score exp(-RMSE/100): {final_exp_score:.4f}\")\n",
    "# print(\"=\"*50)\n",
    "# print(\"\\nThis RMSE is your most reliable estimate for the private leaderboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e586fe",
   "metadata": {},
   "source": [
    "## 7. Train Final Model with Best Parameters\n",
    "\n",
    "Using the best parameters found by Optuna, we'll train the final model on the full training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02fbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Get the best parameters\n",
    "# best_params = study.best_params\n",
    "\n",
    "# # Add fixed parameters\n",
    "# best_params['objective'] = 'reg:squarederror'\n",
    "# best_params['random_state'] = RANDOM_STATE\n",
    "# best_params['n_jobs'] = -1\n",
    "\n",
    "# # Create and train the final model with the best parameters\n",
    "# final_model = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "# print(\"Training final model with best parameters...\")\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate on the training data\n",
    "# train_preds = final_model.predict(X_train)\n",
    "# train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "# train_metric = np.exp(-train_rmse/100)\n",
    "\n",
    "# print(f\"Final model training RMSE: {train_rmse:.4f}\")\n",
    "# print(f\"Final model training metric (exp(-RMSE/100)): {train_metric:.4f}\")\n",
    "\n",
    "# # Feature importance\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# xgb.plot_importance(final_model, max_num_features=10, height=0.8)\n",
    "# plt.title('XGBoost Feature Importance')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20e030-ab50-4cd8-9559-63c9cdc9e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from spatio_temporal import AdvancedSpatioTemporalFeatures, SpatioTemporalDistributionAnalyzer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "# --- Constants and helper functions ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def competition_score(y_true, y_pred):\n",
    "    \"\"\"Calculates the competition score: exp(-RMSE/100)\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return np.exp(-rmse / 100)\n",
    "\n",
    "def get_test_distribution_stats():\n",
    "    \"\"\"Get test distribution stats using SpatioTemporalDistributionAnalyzer\"\"\"\n",
    "    # Create DataFrames with required columns for the analyzer\n",
    "    train_df_for_analysis = train_df.copy()\n",
    "    test_df_for_analysis = test_df.copy()\n",
    "    \n",
    "    # Run the analyzer\n",
    "    analyzer = SpatioTemporalDistributionAnalyzer()\n",
    "    spatial_stats, temporal_stats = analyzer.analyze(train_df_for_analysis, test_df_for_analysis, verbose=False)\n",
    "    \n",
    "    return temporal_stats\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 1. LOAD DATA AND BEST PARAMETERS\n",
    "# ----------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🚀 Generating Final OOF Predictions with AdvancedSpatioTemporalFeatures\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"xgboost_optimization\", storage=\"sqlite:///xgb_optuna.db\")\n",
    "    best_params = study.best_params.copy()\n",
    "    print(\"✅ Successfully loaded best parameters from Optuna study.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not load Optuna study, using placeholder params. Error: {e}\")\n",
    "    best_params = {'learning_rate': 0.05, 'n_estimators': 1500, 'max_depth': 10, \n",
    "                   'n_spatial_clusters': 25, 'n_temporal_clusters': 12} # Example\n",
    "\n",
    "# Extract feature engineering parameters\n",
    "n_spatial_clusters = best_params.pop('n_spatial_clusters', 25)\n",
    "n_temporal_clusters = best_params.pop('n_temporal_clusters', 12)\n",
    "\n",
    "# Prepare XGBoost parameters\n",
    "xgb_best_params = best_params\n",
    "xgb_best_params.update({\n",
    "    'objective': 'reg:squarederror', 'enable_categorical': True, \n",
    "    'random_state': RANDOM_STATE, 'n_jobs': -1\n",
    "})\n",
    "\n",
    "# Calculate test distribution stats using the analyzer\n",
    "temporal_stats = get_test_distribution_stats()\n",
    "print(\"Best parameters loaded and test distribution calculated.\")\n",
    "\n",
    "\n",
    "# 2. SETUP THE OUT-OF-FOLD (OOF) PREDICTION PROCESS\n",
    "# ----------------------------------------------------\n",
    "N_SPLITS = tss.n_splits\n",
    "\n",
    "# Initialize arrays and lists for storing predictions and scores\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "test_preds_from_folds = []\n",
    "fold_train_scores = []\n",
    "fold_val_scores = []\n",
    "\n",
    "print(f\"\\nStarting OOF prediction loop with {N_SPLITS} folds...\")\n",
    "print(f\"Using n_spatial_clusters={n_spatial_clusters}, n_temporal_clusters={n_temporal_clusters}\")\n",
    "\n",
    "\n",
    "# 3. EXECUTE THE OOF LOOP WITH ADVANCED FEATURE ENGINEERING\n",
    "# ----------------------------------------------------\n",
    "for n_fold, (train_idx, val_idx) in enumerate(tss.split(X_train, y_train)):\n",
    "    print(f\"--- Processing Fold {n_fold + 1}/{N_SPLITS} ---\")\n",
    "    \n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx].copy(), X_train.iloc[val_idx].copy()\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    X_test_fold = X_test.copy()\n",
    "\n",
    "    print(\"  - Applying AdvancedSpatioTemporalFeatures...\")\n",
    "    # Apply AdvancedSpatioTemporalFeatures with optimized parameters\n",
    "    fe = AdvancedSpatioTemporalFeatures(\n",
    "        row_only=False,  # Use clustering features inside CV\n",
    "        n_spatial_clusters=n_spatial_clusters,\n",
    "        n_temporal_clusters=n_temporal_clusters,\n",
    "        january_bridge_features=True,  # Use January focus per user request\n",
    "        test_distribution=temporal_stats,\n",
    "        use_distribution_matching=True  # Use distribution matching features\n",
    "    )\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    X_train_enhanced = fe.fit_transform(X_train_fold, y_train_fold)\n",
    "    X_val_enhanced = fe.transform(X_val_fold)\n",
    "    X_test_enhanced = fe.transform(X_test_fold)\n",
    "\n",
    "    y_train_log = np.log1p(y_train_fold)\n",
    "    \n",
    "    print(\"  - Training model...\")\n",
    "    model = xgb.XGBRegressor(**xgb_best_params)\n",
    "    model.fit(X_train_enhanced, y_train_log)\n",
    "    \n",
    "    # --- Calculate and log metrics in the competition format ---\n",
    "    train_preds_log = model.predict(X_train_enhanced)\n",
    "    val_preds_log = model.predict(X_val_enhanced)\n",
    "    \n",
    "    train_preds_orig = np.expm1(train_preds_log)\n",
    "    val_preds_orig = np.expm1(val_preds_log)\n",
    "    \n",
    "    oof_preds[val_idx] = val_preds_orig # Store for overall OOF score\n",
    "    \n",
    "    train_comp_score = competition_score(y_train_fold, train_preds_orig)\n",
    "    val_comp_score = competition_score(y_val_fold, val_preds_orig)\n",
    "    \n",
    "    fold_train_scores.append(train_comp_score)\n",
    "    fold_val_scores.append(val_comp_score)\n",
    "    \n",
    "    print(f\"  - Features: {X_train_enhanced.shape[1]} -> {X_val_enhanced.shape[1]}\")\n",
    "    print(f\"  - Fold {n_fold + 1} Train Score: {train_comp_score:.4f} | Validation Score: {val_comp_score:.4f}\")\n",
    "    \n",
    "    print(\"  - Predicting on test set...\")\n",
    "    test_preds_log = model.predict(X_test_enhanced)\n",
    "    test_preds_from_folds.append(np.expm1(test_preds_log))\n",
    "    \n",
    "    del model, X_train_enhanced, X_val_enhanced, X_test_enhanced, y_train_fold, y_val_fold, fe\n",
    "    gc.collect()\n",
    "\n",
    "# 4. FINALIZE PREDICTIONS AND CREATE SUBMISSION FILE\n",
    "# ----------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 OOF Performance Summary with AdvancedSpatioTemporalFeatures\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "mean_train_score = np.mean(fold_train_scores)\n",
    "std_train_score = np.std(fold_train_scores)\n",
    "mean_val_score = np.mean(fold_val_scores)\n",
    "std_val_score = np.std(fold_val_scores)\n",
    "\n",
    "print(f\"Average Train Competition Score across folds: {mean_train_score:.4f} (+/- {std_train_score:.4f})\")\n",
    "print(f\"Average Validation Competition Score across folds: {mean_val_score:.4f} (+/- {std_val_score:.4f})\")\n",
    "\n",
    "# Calculate the overall OOF score on all combined validation predictions\n",
    "overall_oof_score = competition_score(y_train, oof_preds)\n",
    "print(f\"\\nOverall OOF Competition Score on combined validation sets: {overall_oof_score:.4f}\")\n",
    "\n",
    "# Average the predictions from all folds for a more robust test set prediction\n",
    "final_test_preds = np.mean(test_preds_from_folds, axis=0)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({'id': test_df['id'], 'pollution_value': final_test_preds})\n",
    "submission_df['pollution_value'] = submission_df['pollution_value'].clip(0)\n",
    "\n",
    "# Save the submission file\n",
    "submission_filename = f'submission_enhanced_astf_{overall_oof_score:.4f}.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"\\n✅ Submission file '{submission_filename}' created successfully!\")\n",
    "print(\"Submission file head:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef96703",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions for Submission\n",
    "\n",
    "Now let's generate predictions for the test data using our optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate predictions for the test data\n",
    "# print(\"Generating predictions for test data...\")\n",
    "# test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# # Display a sample of the predictions\n",
    "# print(\"\\nSample predictions:\")\n",
    "# pd.DataFrame({\n",
    "#     'id': test_ids[:5],\n",
    "#     'prediction': test_predictions[:5]\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5534ed",
   "metadata": {},
   "source": [
    "## 9. Create Submission File\n",
    "\n",
    "Finally, we'll create the submission file in the required format with 'id' and 'pollution_value' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the submission DataFrame with the required format\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test_ids,\n",
    "#     'pollution_value': test_predictions\n",
    "# })\n",
    "\n",
    "# # Verify the submission format matches the required format\n",
    "# print(f\"Submission shape: {submission.shape}\")\n",
    "# print(\"Submission columns:\", submission.columns.tolist())\n",
    "# print(\"\\nSubmission sample:\")\n",
    "# display(submission.head())\n",
    "\n",
    "# # Save the submission file\n",
    "# submission_file = 'xgboost_optimized_submission.csv'\n",
    "# submission.to_csv(submission_file, index=False)\n",
    "# print(f\"\\nSubmission saved to {submission_file}\")\n",
    "\n",
    "# # Calculate what the expected metric would be if RMSE was 10\n",
    "# sample_metric = np.exp(-10/100)\n",
    "# print(f\"\\nFor reference, if RMSE = 10, the metric value would be: {sample_metric:.4f}\")\n",
    "# print(f\"Our best model achieved a metric value of: {trial.value:.4f} on validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d49465",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. Loaded and explored the dataset\n",
    "2. Prepared features and target variables\n",
    "3. Set up TimeSeriesSplit cross-validation with 5 folds\n",
    "4. Created a custom scoring metric to maximize exp(-RMSE/100)\n",
    "5. Defined an extensive hyperparameter search space for XGBoost\n",
    "6. Optimized the XGBoost model using Optuna\n",
    "7. Trained a final model with the best parameters\n",
    "8. Generated predictions and created a submission file\n",
    "\n",
    "The final submission file contains the predicted pollution values for the test set in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d9e45-b342-4c45-bf7c-b3d901197400",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
