{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231ac0f8",
   "metadata": {},
   "source": [
    "# XGBoost Regressor Hyperparameter Optimization\n",
    "\n",
    "This notebook demonstrates how to optimize XGBoost regressor hyperparameters using the following:\n",
    "- TimeSeriesSplit with 5 folds for cross-validation\n",
    "- Optuna for hyperparameter optimization\n",
    "- The tabularaml library's cv.py function for evaluation\n",
    "- Optimization metric: exp(-RMSE/100)\n",
    "\n",
    "The goal is to create a submission file with columns 'id' and 'pollution_value' containing our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6917190",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb13348-2c12-467f-82a7-c19f4506cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q numpy pandas optuna \"xgboost>=1.7.0\" scikit-learn category_encoders matplotlib seaborn cloudpickle optuna-integration[xgboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb77121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c3538",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data\n",
    "\n",
    "Let's load the training and test datasets. We'll assume the files are in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b464f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re\n",
    "from tabularaml.generate.features import FeatureGenerator\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_format = pd.read_csv('submission_example.csv')\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "# Assume a dummy year since it's not provided\n",
    "year = 2023\n",
    "# Construct datetime from day_of_year and hour\n",
    "train_df['datetime'] = pd.to_datetime(train_df['day_of_year'], format='%j', errors='coerce') \\\n",
    "                       + pd.to_timedelta(train_df['hour'], unit='h')\n",
    "train_df['datetime'] = train_df['datetime'].apply(\n",
    "    lambda dt: dt.replace(year=year) if pd.notnull(dt) else dt\n",
    ")\n",
    "# Sort by datetime column\n",
    "train_df = train_df.sort_values(by='datetime')\n",
    "# Drop the temporary datetime column\n",
    "train_df = train_df.drop(columns='datetime')\n",
    "# Reset the index\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "X_train = train_df.drop([\n",
    "    \"id\",\n",
    "    \"pollution_value\"], axis=1).copy()\n",
    "X_train_before = X_train.copy()\n",
    "X_test = test_df.copy()\n",
    "\n",
    "DIR = \"model_redone\"\n",
    "\n",
    "# if os.path.isdir(DIR):\n",
    "#     for f in sorted(\n",
    "#         (f for f in os.listdir(DIR) if re.match(r\"feature_generator_\\d+\\.pkl\", f)),\n",
    "#         key=lambda x: int(re.search(r\"\\d+\", x).group())\n",
    "#     ):\n",
    "#         try:\n",
    "#             gen = FeatureGenerator.load(f\"{DIR}/{f}\")\n",
    "#             X_train = gen.fit_transform(X_train)\n",
    "#             X_test = gen.transform(X_test)\n",
    "#             print(f\"Loaded and transformed with {f} successfully.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Skipped {f}: {e}\")\n",
    "\n",
    "y_train = train_df[\"pollution_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9477c",
   "metadata": {},
   "source": [
    "## 3. Prepare Features and Target\n",
    "\n",
    "Let's prepare the features and target variable for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf5b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (7649, 6)\n",
      "Target shape: (7649,)\n",
      "Test features shape: (2739, 7)\n",
      "\n",
      "Missing values in training features:\n",
      "latitude       13\n",
      "longitude      13\n",
      "day_of_year     0\n",
      "day_of_week     0\n",
      "hour            0\n",
      "month           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in target:\n",
      "0\n",
      "\n",
      "Missing values in test features:\n",
      "id             0\n",
      "latitude       0\n",
      "longitude      0\n",
      "day_of_year    0\n",
      "day_of_week    0\n",
      "hour           0\n",
      "month          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_ids = test_df['id'].copy() \n",
    "# test_ids = test_data['id']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training features:\")\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in target:\")\n",
    "print(y_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test features:\")\n",
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36975572",
   "metadata": {},
   "source": [
    "## 4. Set Up TimeSeriesSplit Cross-Validation\n",
    "\n",
    "For time series data, we need to use a time-based validation approach. We'll use `TimeSeriesSplit` from scikit-learn with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2557f7-5449-4c8c-ae73-03d450758f5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import BaseCrossValidator\n",
    "import numpy as np\n",
    "\n",
    "class FixedWindowTimeSeriesSplit(BaseCrossValidator):\n",
    "    \"\"\"\n",
    "    Custom time-series cross-validator with fixed-size test windows.\n",
    "    Ensures every fold has meaningful training data and proper temporal ordering.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int\n",
    "        Number of folds. Must be at least 1.\n",
    "    test_size : int\n",
    "        Number of samples in each test fold.\n",
    "    gap : int, default=0\n",
    "        Number of samples to exclude between train and test sets.\n",
    "    min_train_size : int, default=None\n",
    "        Minimum number of training samples required. If None, defaults to test_size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_splits=5, test_size=2700, gap=0, min_train_size=None):\n",
    "        if n_splits < 1:\n",
    "            raise ValueError(\"n_splits must be at least 1.\")\n",
    "        if test_size < 1:\n",
    "            raise ValueError(\"test_size must be at least 1.\")\n",
    "        if gap < 0:\n",
    "            raise ValueError(\"gap must be non-negative.\")\n",
    "        \n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.gap = gap\n",
    "        self.min_train_size = min_train_size or test_size\n",
    "        \n",
    "        if self.min_train_size < 1:\n",
    "            raise ValueError(\"min_train_size must be at least 1.\")\n",
    "    \n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        \n",
    "        # Check if we have enough data for at least one split\n",
    "        min_required = self.min_train_size + self.gap + self.test_size\n",
    "        if min_required > n_samples:\n",
    "            raise ValueError(\n",
    "                f\"Not enough samples. Need at least {min_required} samples \"\n",
    "                f\"(min_train_size={self.min_train_size} + gap={self.gap} + test_size={self.test_size}), \"\n",
    "                f\"but got {n_samples}.\"\n",
    "            )\n",
    "        \n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        if self.n_splits == 1:\n",
    "            # Single window: place test at the end, ensure minimum training size\n",
    "            test_end = n_samples\n",
    "            test_start = test_end - self.test_size\n",
    "            train_end = test_start - self.gap\n",
    "            \n",
    "            # Ensure we have minimum training size\n",
    "            if train_end < self.min_train_size:\n",
    "                train_end = self.min_train_size\n",
    "                test_start = train_end + self.gap\n",
    "                test_end = test_start + self.test_size\n",
    "                \n",
    "                # Check if this fits within our data\n",
    "                if test_end > n_samples:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot fit single split with constraints. \"\n",
    "                        f\"Need {self.min_train_size + self.gap + self.test_size} samples, got {n_samples}.\"\n",
    "                    )\n",
    "            \n",
    "            train_idx = indices[:train_end]\n",
    "            test_idx = indices[test_start:test_end]\n",
    "            yield train_idx, test_idx\n",
    "            return\n",
    "        \n",
    "        # For multiple splits, distribute test windows\n",
    "        # Last test window ends at n_samples, work backwards\n",
    "        test_windows = []\n",
    "        \n",
    "        # Calculate positions for test windows\n",
    "        # We want to distribute them evenly in the available space\n",
    "        latest_test_end = n_samples\n",
    "        earliest_test_start = self.min_train_size + self.gap\n",
    "        \n",
    "        # Available space for test window starts\n",
    "        available_space = latest_test_end - self.test_size - earliest_test_start\n",
    "        \n",
    "        if available_space < 0:\n",
    "            raise ValueError(\n",
    "                \"Cannot create requested splits. Try reducing n_splits, test_size, or min_train_size.\"\n",
    "            )\n",
    "        \n",
    "        # Calculate step size between test windows\n",
    "        if self.n_splits == 1:\n",
    "            step = 0\n",
    "        else:\n",
    "            step = available_space / (self.n_splits - 1)\n",
    "        \n",
    "        # Generate test windows from last to first\n",
    "        for i in range(self.n_splits):\n",
    "            # Calculate test window position\n",
    "            test_start = int(earliest_test_start + i * step)\n",
    "            test_end = test_start + self.test_size\n",
    "            \n",
    "            # Ensure test window doesn't exceed data bounds\n",
    "            if test_end > n_samples:\n",
    "                test_end = n_samples\n",
    "                test_start = test_end - self.test_size\n",
    "            \n",
    "            # Calculate training end (before gap)\n",
    "            train_end = test_start - self.gap\n",
    "            \n",
    "            # Ensure minimum training size\n",
    "            if train_end < self.min_train_size:\n",
    "                raise ValueError(\n",
    "                    f\"Split {i+1} would have insufficient training data. \"\n",
    "                    f\"Try reducing n_splits or min_train_size.\"\n",
    "                )\n",
    "            \n",
    "            train_idx = indices[:train_end]\n",
    "            test_idx = indices[test_start:test_end]\n",
    "            \n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abea518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tss = FixedWindowTimeSeriesSplit(n_splits=5, test_size=2700)\n",
    "\n",
    "\n",
    "# Visualize the TimeSeriesSplit\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tss.split(X_train)):\n",
    "    plt.scatter(test_index, [i+0.5]*len(test_index), \n",
    "                c='red', s=10, label='Testing set' if i == 0 else \"\")\n",
    "    plt.scatter(train_index, [i+0.5]*len(train_index), \n",
    "                c='blue', s=10, label='Training set' if i == 0 else \"\")\n",
    "\n",
    "plt.yticks(np.arange(5) + 0.5, [f'Fold {i+1}' for i in range(5)])\n",
    "plt.title('TimeSeriesSplit with 5 folds')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fff938-8892-4f9f-ae0d-59bcf55bbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "游대 Fold 1\n",
      "  - Train size: 2700, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1613\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "5     162\n",
      "6     208\n",
      "7     372\n",
      "8    1958\n",
      "\n",
      "游대 Fold 2\n",
      "  - Train size: 3262, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      192\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "7     180\n",
      "8    1961\n",
      "9     559\n",
      "\n",
      "游대 Fold 3\n",
      "  - Train size: 3824, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      372\n",
      "8      382\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "8    1579\n",
      "9    1121\n",
      "\n",
      "游대 Fold 4\n",
      "  - Train size: 4386, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      372\n",
      "8      944\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "8     1017\n",
      "9     1273\n",
      "10     410\n",
      "\n",
      "游대 Fold 5\n",
      "  - Train size: 4949, Val size: 2700\n",
      "  - Train months:\n",
      " month\n",
      "1      334\n",
      "2      155\n",
      "3      191\n",
      "4      245\n",
      "5     1775\n",
      "6      208\n",
      "7      372\n",
      "8     1507\n",
      "12     162\n",
      "  - Val months:\n",
      " month\n",
      "8      454\n",
      "9     1273\n",
      "10     555\n",
      "11     219\n",
      "12     199\n"
     ]
    }
   ],
   "source": [
    "for i, (train_idx, val_idx) in enumerate(tss.split(X_train, y_train), 1):\n",
    "    train_months = X_train.iloc[train_idx][\"month\"].value_counts().sort_index()\n",
    "    val_months = X_train.iloc[val_idx][\"month\"].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\n游대 Fold {i}\")\n",
    "    print(f\"  - Train size: {len(train_idx)}, Val size: {len(val_idx)}\")\n",
    "    print(\"  - Train months:\\n\", train_months.to_string())\n",
    "    print(\"  - Val months:\\n\", val_months.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ff60d",
   "metadata": {},
   "source": [
    "## 5. Define Optuna Objective Function for XGBoost GBRegressor\n",
    "\n",
    "Now, we'll define the Optuna objective function to optimize XGBoost hyperparameters using our custom metric and TimeSeriesSplit cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71ad2fa-3b07-4597-b3f4-556f5e8ef81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from spatio_temporal import AdvancedSpatioTemporalFeatures, SpatioTemporalDistributionAnalyzer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to optimize XGBoost hyperparameters with AdvancedSpatioTemporalFeatures\n",
    "    \"\"\"\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 2000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.5, 20),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 1.0),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.4, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 0, 1000),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 512),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'enable_categorical': True,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1  # Use all CPU cores\n",
    "    }\n",
    "    \n",
    "    # AdvancedSpatioTemporalFeatures hyperparameters\n",
    "    n_spatial_clusters = trial.suggest_int('n_spatial_clusters', 15, 35)\n",
    "    n_temporal_clusters = trial.suggest_int('n_temporal_clusters', 8, 18)\n",
    "    \n",
    "    # Use predefined splitter for cross-validation\n",
    "    folds = tss\n",
    "    \n",
    "    # Calculate test distribution stats using the analyzer from spatio_temporal.py\n",
    "    temporal_stats = get_test_distribution_stats()\n",
    "    \n",
    "    # Use existing X_train and y_train\n",
    "    X_base = X_train.copy()\n",
    "    y = y_train.copy()\n",
    "    \n",
    "    # Apply log transformation to the target variable\n",
    "    y = np.log1p(y)\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_base, y)):\n",
    "        # Split base features\n",
    "        X_train_fold = X_base.iloc[train_idx].copy()\n",
    "        X_valid_fold = X_base.iloc[valid_idx].copy()\n",
    "        X_test_fold = X_test.copy()\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        y_valid_fold = y.iloc[valid_idx]\n",
    "\n",
    "        # Apply AdvancedSpatioTemporalFeatures with optimized parameters\n",
    "        fe = AdvancedSpatioTemporalFeatures(\n",
    "            row_only=False,  # Use clustering features inside CV\n",
    "            n_spatial_clusters=n_spatial_clusters,\n",
    "            n_temporal_clusters=n_temporal_clusters,\n",
    "            january_bridge_features=True,  # Use January focus per user request\n",
    "            test_distribution=temporal_stats,\n",
    "            use_distribution_matching=True  # Use distribution matching features\n",
    "        )\n",
    "        \n",
    "        # Apply feature engineering\n",
    "        X_train_enhanced = fe.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_valid_enhanced = fe.transform(X_valid_fold)\n",
    "        X_test_enhanced = fe.transform(X_test_fold)  # Keep for consistency\n",
    "        \n",
    "        # Train model on this fold\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train_enhanced, y_train_fold)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred_fold = model.predict(X_valid_enhanced)\n",
    "        \n",
    "        # Inverse transform predictions and actual values to calculate RMSE on original scale\n",
    "        y_pred_orig_scale = np.expm1(y_pred_fold)\n",
    "        y_valid_orig_scale = np.expm1(y_valid_fold)\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid_orig_scale, y_pred_orig_scale))\n",
    "        \n",
    "        # Convert to exponential score format\n",
    "        exp_score = np.exp(-rmse / 100)\n",
    "        fold_scores.append(exp_score)\n",
    "    \n",
    "    # Return the mean validation score to maximize\n",
    "    return np.mean(fold_scores)\n",
    "\n",
    "\n",
    "def get_test_distribution_stats():\n",
    "    \"\"\"Get test distribution stats using SpatioTemporalDistributionAnalyzer\"\"\"\n",
    "    # Create dummy DataFrames with required columns for the analyzer\n",
    "    train_df_for_analysis = train_df.copy()\n",
    "    test_df_for_analysis = test_df.copy()\n",
    "    \n",
    "    # Run the analyzer\n",
    "    analyzer = SpatioTemporalDistributionAnalyzer()\n",
    "    spatial_stats, temporal_stats = analyzer.analyze(train_df_for_analysis, test_df_for_analysis, verbose=False)\n",
    "    \n",
    "    return temporal_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b500b2a",
   "metadata": {},
   "source": [
    "## 6. Run Optuna Optimization\n",
    "\n",
    "Now we'll run the optimization process to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be1d84-5a88-4149-961e-6ba3fe5ba8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-15 03:44:26,268] A new study created in RDB with name: xgboost_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游댌  Running 500 trials 뵢n"
     ]
    }
   ],
   "source": [
    "# 較較較較較較較較較較較較較較較較較較較較 4. Sampler & pruner 較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "sampler = TPESampler(\n",
    "    multivariate=True,\n",
    "    group=True,\n",
    "    n_startup_trials=20,\n",
    "    constant_liar=True,   # set False if running strictly single-threaded\n",
    "    seed=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "pruner = HyperbandPruner(\n",
    "    min_resource=1,       # first boosting round\n",
    "    max_resource=1000,    # must match the upper bound of n_estimators\n",
    "    reduction_factor=3,\n",
    ")\n",
    "\n",
    "# 較較較較較較較較較較較較較較較較較較較較 5. Create / resume study 較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"xgboost_optimization\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    storage=\"sqlite:///xgb_optuna.db\",  # makes the study persistent\n",
    "    load_if_exists=True,               # resume if the DB already exists\n",
    ")\n",
    "\n",
    "# 較較較較較較較較較較較較較較較較較較較較 6. Optimise 較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\n",
    "N_TRIALS = 500\n",
    "print(f\"游댌  Running {N_TRIALS} trials 뵢")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# 較較較較較較較較較較較較較較較較較較較較 7. Results 較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\n",
    "best = study.best_trial\n",
    "print(\"\\n游꿢  Best trial\")\n",
    "print(f\"    exp(-RMSE/100) : {best.value:.4f}\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"    {k:<18}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85aac9-30f4-4ea0-acb3-1f55c03d73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_trial\n",
    "print(\"\\n游꿢  Best trial\")\n",
    "print(f\"    exp(-RMSE/100) : {best.value:.4f}\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"    {k:<18}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e82624-e589-4e83-b645-f74c87034bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimization process\n",
    "plt.figure(figsize=(10, 6))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "plt.title('Optimization History')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)\n",
    "plt.title('Hyperparameter Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c6b35-3e48-431b-96e9-55eca2c2c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import optuna\n",
    "\n",
    "# # Assume the following variables already exist from your setup before Optuna:\n",
    "# # X_train: pd.DataFrame with features, including the original 'month' column\n",
    "# # y_train: pd.Series with the target 'pollution_value'\n",
    "# # create_cyclical_features: The function you defined\n",
    "# # RANDOM_STATE: The integer seed you used\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 1. LOAD THE COMPLETED STUDY AND GET THE BEST PARAMETERS\n",
    "# # ---------------------------------------------------------------------------\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"游  Starting Final Sanity Check on the 'Golden' January Fold\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# try:\n",
    "#     # Load the study from the database\n",
    "#     study = optuna.load_study(\n",
    "#         study_name=\"xgboost_optimization\",\n",
    "#         storage=\"sqlite:///xgb_optuna.db\"\n",
    "#     )\n",
    "#     best_params = study.best_params.copy() # Use .copy() to avoid modifying the original\n",
    "#     print(\"九 Successfully loaded best parameters from Optuna study.\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"仇 Could not load study due to: {e}. Please ensure the study exists.\")\n",
    "#     # In a real run, you might want to exit here or use default parameters\n",
    "#     # For this example, we'll stop if the study isn't found.\n",
    "#     exit()\n",
    "\n",
    "# # Separate the model hyperparameters from our custom preprocessing hyperparameter\n",
    "# n_clusters_best = best_params.pop('n_clusters')\n",
    "# xgb_best_params = best_params\n",
    "\n",
    "# # Add back the fixed XGBoost parameters needed for instantiation\n",
    "# xgb_best_params.update({\n",
    "#     'objective': 'reg:squarederror',\n",
    "#     'enable_categorical': True,\n",
    "#     'random_state': RANDOM_STATE,\n",
    "#     'n_jobs': -1\n",
    "# })\n",
    "\n",
    "# print(\"\\n游늶 Best Hyperparameters for Final Model:\")\n",
    "# for k, v in xgb_best_params.items():\n",
    "#     print(f\"    {k:<18}: {v}\")\n",
    "# print(f\"    {'n_clusters':<18}: {n_clusters_best}\")\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 2. CREATE THE \"GOLDEN\" SPLIT FROM EXISTING X_train and y_train\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # Create boolean masks based on the 'month' column in the existing X_train\n",
    "# train_mask = X_train['month'] != 1\n",
    "# val_mask = X_train['month'] == 1\n",
    "\n",
    "# # Create the final training and validation sets using the masks\n",
    "# X_train_final = X_train.loc[train_mask].copy()\n",
    "# X_val_final = X_train.loc[val_mask].copy()\n",
    "\n",
    "# y_train_final = y_train.loc[train_mask].copy()\n",
    "# y_val_final = y_train.loc[val_mask].copy() # This is the true target for the golden fold\n",
    "\n",
    "# print(f\"\\nGolden Split created from existing X_train:\")\n",
    "# print(f\"  - Final Train size: {len(X_train_final)}\")\n",
    "# print(f\"  - Final Validation size: {len(X_val_final)}\")\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 3. APPLY THE IDENTICAL PREPROCESSING PIPELINE\n",
    "# # ---------------------------------------------------------------------------\n",
    "# print(\"\\n游댢 Applying preprocessing pipeline...\")\n",
    "\n",
    "# # a) Cyclical Features\n",
    "# # This function should drop the original time columns as it did in the objective\n",
    "# X_train_final = create_cyclical_features(X_train_final)\n",
    "# X_val_final = create_cyclical_features(X_val_final)\n",
    "\n",
    "# # b) K-Means Clustering Feature\n",
    "# if 'latitude' in X_train_final.columns and 'longitude' in X_train_final.columns:\n",
    "#     print(f\"  - Fitting KMeans with n_clusters={n_clusters_best}...\")\n",
    "#     kmeans = KMeans(n_clusters=n_clusters_best, random_state=RANDOM_STATE, n_init='auto')\n",
    "    \n",
    "#     # Impute NaNs temporarily just for clustering\n",
    "#     lat_mean = X_train_final['latitude'].mean()\n",
    "#     lon_mean = X_train_final['longitude'].mean()\n",
    "#     train_coords_temp = X_train_final[['latitude', 'longitude']].fillna({'latitude': lat_mean, 'longitude': lon_mean})\n",
    "#     valid_coords_temp = X_val_final[['latitude', 'longitude']].fillna({'latitude': lat_mean, 'longitude': lon_mean})\n",
    "    \n",
    "#     kmeans.fit(train_coords_temp)\n",
    "    \n",
    "#     X_train_final['cluster'] = kmeans.predict(train_coords_temp)\n",
    "#     X_val_final['cluster'] = kmeans.predict(valid_coords_temp)\n",
    "#     print(\"  - Cluster feature added.\")\n",
    "\n",
    "# # c) Log-transform the target for training\n",
    "# y_train_log = np.log1p(y_train_final)\n",
    "\n",
    "# # d) Align columns to ensure consistency\n",
    "# common_features = list(X_train_final.columns.intersection(X_val_final.columns))\n",
    "# X_train_final = X_train_final[common_features]\n",
    "# X_val_final = X_val_final[common_features]\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # 4. TRAIN THE FINAL MODEL AND EVALUATE\n",
    "# # ---------------------------------------------------------------------------\n",
    "# print(\"\\n游 Training final model with best parameters...\")\n",
    "# final_model = xgb.XGBRegressor(**xgb_best_params)\n",
    "\n",
    "# final_model.fit(X_train_final, y_train_log)\n",
    "\n",
    "# print(\"游늳 Predicting on the January validation set...\")\n",
    "# y_pred_log = final_model.predict(X_val_final)\n",
    "\n",
    "# # Inverse transform predictions to get them back to the original scale\n",
    "# y_pred_orig_scale = np.expm1(y_pred_log)\n",
    "\n",
    "# # Calculate the final, reliable RMSE on the original scale validation target\n",
    "# final_rmse = np.sqrt(mean_squared_error(y_val_final, y_pred_orig_scale))\n",
    "# final_exp_score = np.exp(-final_rmse / 100)\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"游끥 FINAL PERFORMANCE ESTIMATE 游끥\")\n",
    "# print(\"=\"*50)\n",
    "# print(f\"  RMSE on 'Golden' January Fold: {final_rmse:.4f}\")\n",
    "# print(f\"  Competition Score exp(-RMSE/100): {final_exp_score:.4f}\")\n",
    "# print(\"=\"*50)\n",
    "# print(\"\\nThis RMSE is your most reliable estimate for the private leaderboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e586fe",
   "metadata": {},
   "source": [
    "## 7. Train Final Model with Best Parameters\n",
    "\n",
    "Using the best parameters found by Optuna, we'll train the final model on the full training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02fbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Get the best parameters\n",
    "# best_params = study.best_params\n",
    "\n",
    "# # Add fixed parameters\n",
    "# best_params['objective'] = 'reg:squarederror'\n",
    "# best_params['random_state'] = RANDOM_STATE\n",
    "# best_params['n_jobs'] = -1\n",
    "\n",
    "# # Create and train the final model with the best parameters\n",
    "# final_model = xgb.XGBRegressor(**best_params)\n",
    "\n",
    "# print(\"Training final model with best parameters...\")\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate on the training data\n",
    "# train_preds = final_model.predict(X_train)\n",
    "# train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "# train_metric = np.exp(-train_rmse/100)\n",
    "\n",
    "# print(f\"Final model training RMSE: {train_rmse:.4f}\")\n",
    "# print(f\"Final model training metric (exp(-RMSE/100)): {train_metric:.4f}\")\n",
    "\n",
    "# # Feature importance\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# xgb.plot_importance(final_model, max_num_features=10, height=0.8)\n",
    "# plt.title('XGBoost Feature Importance')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20e030-ab50-4cd8-9559-63c9cdc9e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from spatio_temporal import AdvancedSpatioTemporalFeatures, SpatioTemporalDistributionAnalyzer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "# --- Constants and helper functions ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def competition_score(y_true, y_pred):\n",
    "    \"\"\"Calculates the competition score: exp(-RMSE/100)\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return np.exp(-rmse / 100)\n",
    "\n",
    "def get_test_distribution_stats():\n",
    "    \"\"\"Get test distribution stats using SpatioTemporalDistributionAnalyzer\"\"\"\n",
    "    # Create DataFrames with required columns for the analyzer\n",
    "    train_df_for_analysis = train_df.copy()\n",
    "    test_df_for_analysis = test_df.copy()\n",
    "    \n",
    "    # Run the analyzer\n",
    "    analyzer = SpatioTemporalDistributionAnalyzer()\n",
    "    spatial_stats, temporal_stats = analyzer.analyze(train_df_for_analysis, test_df_for_analysis, verbose=False)\n",
    "    \n",
    "    return temporal_stats\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 1. LOAD DATA AND BEST PARAMETERS\n",
    "# ----------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"游 Generating Final OOF Predictions with AdvancedSpatioTemporalFeatures\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    study = optuna.load_study(study_name=\"xgboost_optimization\", storage=\"sqlite:///xgb_optuna.db\")\n",
    "    best_params = study.best_params.copy()\n",
    "    print(\"九 Successfully loaded best parameters from Optuna study.\")\n",
    "except Exception as e:\n",
    "    print(f\"仇 Could not load Optuna study, using placeholder params. Error: {e}\")\n",
    "    best_params = {'learning_rate': 0.05, 'n_estimators': 1500, 'max_depth': 10, \n",
    "                   'n_spatial_clusters': 25, 'n_temporal_clusters': 12} # Example\n",
    "\n",
    "# Extract feature engineering parameters\n",
    "n_spatial_clusters = best_params.pop('n_spatial_clusters', 25)\n",
    "n_temporal_clusters = best_params.pop('n_temporal_clusters', 12)\n",
    "\n",
    "# Prepare XGBoost parameters\n",
    "xgb_best_params = best_params\n",
    "xgb_best_params.update({\n",
    "    'objective': 'reg:squarederror', 'enable_categorical': True, \n",
    "    'random_state': RANDOM_STATE, 'n_jobs': -1\n",
    "})\n",
    "\n",
    "# Calculate test distribution stats using the analyzer\n",
    "temporal_stats = get_test_distribution_stats()\n",
    "print(\"Best parameters loaded and test distribution calculated.\")\n",
    "\n",
    "\n",
    "# 2. SETUP THE OUT-OF-FOLD (OOF) PREDICTION PROCESS\n",
    "# ----------------------------------------------------\n",
    "N_SPLITS = tss.n_splits\n",
    "\n",
    "# Initialize arrays and lists for storing predictions and scores\n",
    "oof_preds = np.zeros(len(X_train))\n",
    "test_preds_from_folds = []\n",
    "fold_train_scores = []\n",
    "fold_val_scores = []\n",
    "\n",
    "print(f\"\\nStarting OOF prediction loop with {N_SPLITS} folds...\")\n",
    "print(f\"Using n_spatial_clusters={n_spatial_clusters}, n_temporal_clusters={n_temporal_clusters}\")\n",
    "\n",
    "\n",
    "# 3. EXECUTE THE OOF LOOP WITH ADVANCED FEATURE ENGINEERING\n",
    "# ----------------------------------------------------\n",
    "for n_fold, (train_idx, val_idx) in enumerate(tss.split(X_train, y_train)):\n",
    "    print(f\"--- Processing Fold {n_fold + 1}/{N_SPLITS} ---\")\n",
    "    \n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx].copy(), X_train.iloc[val_idx].copy()\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    X_test_fold = X_test.copy()\n",
    "\n",
    "    print(\"  - Applying AdvancedSpatioTemporalFeatures...\")\n",
    "    # Apply AdvancedSpatioTemporalFeatures with optimized parameters\n",
    "    fe = AdvancedSpatioTemporalFeatures(\n",
    "        row_only=False,  # Use clustering features inside CV\n",
    "        n_spatial_clusters=n_spatial_clusters,\n",
    "        n_temporal_clusters=n_temporal_clusters,\n",
    "        january_bridge_features=True,  # Use January focus per user request\n",
    "        test_distribution=temporal_stats,\n",
    "        use_distribution_matching=True  # Use distribution matching features\n",
    "    )\n",
    "    \n",
    "    # Apply feature engineering\n",
    "    X_train_enhanced = fe.fit_transform(X_train_fold, y_train_fold)\n",
    "    X_val_enhanced = fe.transform(X_val_fold)\n",
    "    X_test_enhanced = fe.transform(X_test_fold)\n",
    "\n",
    "    y_train_log = np.log1p(y_train_fold)\n",
    "    \n",
    "    print(\"  - Training model...\")\n",
    "    model = xgb.XGBRegressor(**xgb_best_params)\n",
    "    model.fit(X_train_enhanced, y_train_log)\n",
    "    \n",
    "    # --- Calculate and log metrics in the competition format ---\n",
    "    train_preds_log = model.predict(X_train_enhanced)\n",
    "    val_preds_log = model.predict(X_val_enhanced)\n",
    "    \n",
    "    train_preds_orig = np.expm1(train_preds_log)\n",
    "    val_preds_orig = np.expm1(val_preds_log)\n",
    "    \n",
    "    oof_preds[val_idx] = val_preds_orig # Store for overall OOF score\n",
    "    \n",
    "    train_comp_score = competition_score(y_train_fold, train_preds_orig)\n",
    "    val_comp_score = competition_score(y_val_fold, val_preds_orig)\n",
    "    \n",
    "    fold_train_scores.append(train_comp_score)\n",
    "    fold_val_scores.append(val_comp_score)\n",
    "    \n",
    "    print(f\"  - Features: {X_train_enhanced.shape[1]} -> {X_val_enhanced.shape[1]}\")\n",
    "    print(f\"  - Fold {n_fold + 1} Train Score: {train_comp_score:.4f} | Validation Score: {val_comp_score:.4f}\")\n",
    "    \n",
    "    print(\"  - Predicting on test set...\")\n",
    "    test_preds_log = model.predict(X_test_enhanced)\n",
    "    test_preds_from_folds.append(np.expm1(test_preds_log))\n",
    "    \n",
    "    del model, X_train_enhanced, X_val_enhanced, X_test_enhanced, y_train_fold, y_val_fold, fe\n",
    "    gc.collect()\n",
    "\n",
    "# 4. FINALIZE PREDICTIONS AND CREATE SUBMISSION FILE\n",
    "# ----------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"游늵 OOF Performance Summary with AdvancedSpatioTemporalFeatures\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "mean_train_score = np.mean(fold_train_scores)\n",
    "std_train_score = np.std(fold_train_scores)\n",
    "mean_val_score = np.mean(fold_val_scores)\n",
    "std_val_score = np.std(fold_val_scores)\n",
    "\n",
    "print(f\"Average Train Competition Score across folds: {mean_train_score:.4f} (+/- {std_train_score:.4f})\")\n",
    "print(f\"Average Validation Competition Score across folds: {mean_val_score:.4f} (+/- {std_val_score:.4f})\")\n",
    "\n",
    "# Calculate the overall OOF score on all combined validation predictions\n",
    "overall_oof_score = competition_score(y_train, oof_preds)\n",
    "print(f\"\\nOverall OOF Competition Score on combined validation sets: {overall_oof_score:.4f}\")\n",
    "\n",
    "# Average the predictions from all folds for a more robust test set prediction\n",
    "final_test_preds = np.mean(test_preds_from_folds, axis=0)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({'id': test_df['id'], 'pollution_value': final_test_preds})\n",
    "submission_df['pollution_value'] = submission_df['pollution_value'].clip(0)\n",
    "\n",
    "# Save the submission file\n",
    "submission_filename = f'submission_enhanced_astf_{overall_oof_score:.4f}.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"\\n九 Submission file '{submission_filename}' created successfully!\")\n",
    "print(\"Submission file head:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef96703",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions for Submission\n",
    "\n",
    "Now let's generate predictions for the test data using our optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate predictions for the test data\n",
    "# print(\"Generating predictions for test data...\")\n",
    "# test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# # Display a sample of the predictions\n",
    "# print(\"\\nSample predictions:\")\n",
    "# pd.DataFrame({\n",
    "#     'id': test_ids[:5],\n",
    "#     'prediction': test_predictions[:5]\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5534ed",
   "metadata": {},
   "source": [
    "## 9. Create Submission File\n",
    "\n",
    "Finally, we'll create the submission file in the required format with 'id' and 'pollution_value' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the submission DataFrame with the required format\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': test_ids,\n",
    "#     'pollution_value': test_predictions\n",
    "# })\n",
    "\n",
    "# # Verify the submission format matches the required format\n",
    "# print(f\"Submission shape: {submission.shape}\")\n",
    "# print(\"Submission columns:\", submission.columns.tolist())\n",
    "# print(\"\\nSubmission sample:\")\n",
    "# display(submission.head())\n",
    "\n",
    "# # Save the submission file\n",
    "# submission_file = 'xgboost_optimized_submission.csv'\n",
    "# submission.to_csv(submission_file, index=False)\n",
    "# print(f\"\\nSubmission saved to {submission_file}\")\n",
    "\n",
    "# # Calculate what the expected metric would be if RMSE was 10\n",
    "# sample_metric = np.exp(-10/100)\n",
    "# print(f\"\\nFor reference, if RMSE = 10, the metric value would be: {sample_metric:.4f}\")\n",
    "# print(f\"Our best model achieved a metric value of: {trial.value:.4f} on validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d49465",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. Loaded and explored the dataset\n",
    "2. Prepared features and target variables\n",
    "3. Set up TimeSeriesSplit cross-validation with 5 folds\n",
    "4. Created a custom scoring metric to maximize exp(-RMSE/100)\n",
    "5. Defined an extensive hyperparameter search space for XGBoost\n",
    "6. Optimized the XGBoost model using Optuna\n",
    "7. Trained a final model with the best parameters\n",
    "8. Generated predictions and created a submission file\n",
    "\n",
    "The final submission file contains the predicted pollution values for the test set in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d9e45-b342-4c45-bf7c-b3d901197400",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
