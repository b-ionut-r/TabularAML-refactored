{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ad1bf5-e1c2-4e3f-88d2-29de5b803cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q numpy scikit-learn pandas xgboost lightgbm category_encoders matplotlib seaborn cloudpickle shap optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oeobb8htb7g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# REPRODUCIBILITY: Set all random seeds before any other imports\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from spatio_temporal import *\n",
    "\n",
    "# Set all random seeds for full reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "print(\"‚úÖ All random seeds set for reproducibility\")\n",
    "\n",
    "DIR = \"model_spatiotemporal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a887183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667f2628-2dca-4c5b-825c-fd39c1f26624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume a dummy year since it's not provided\n",
    "year = 2023\n",
    "\n",
    "# Construct datetime from day_of_year and hour\n",
    "train_df['datetime'] = pd.to_datetime(train_df['day_of_year'], format='%j', errors='coerce') \\\n",
    "                       + pd.to_timedelta(train_df['hour'], unit='h')\n",
    "train_df['datetime'] = train_df['datetime'].apply(\n",
    "    lambda dt: dt.replace(year=year) if pd.notnull(dt) else dt\n",
    ")\n",
    "\n",
    "# Sort by datetime column\n",
    "train_df = train_df.sort_values(by='datetime')\n",
    "\n",
    "# Drop the temporary datetime column\n",
    "train_df = train_df.drop(columns='datetime')\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True) # CRUCIAL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ad7c2c-3555-4e36-b1fa-7173a8d8535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ": Analyzing distribution shifts...\n",
      "Analyzing distribution differences...\n",
      "\n",
      "Spatial Distribution:\n",
      "  Latitude KS: 0.3457 (p=1.52e-214)\n",
      "  Longitude KS: 0.2957 (p=3.77e-156)\n",
      "\n",
      "Temporal Distribution Shifts:\n",
      "  hour: Wasserstein=3.3287 (significant, p=1.29e-252)\n",
      "  day_of_week: Wasserstein=1.8408 (significant, p=4.61e-321)\n",
      "  month: Wasserstein=6.1064 (significant, p=0.00e+00)\n",
      "  day_of_year: Wasserstein=175.2113 (significant, p=0.00e+00)\n",
      "Significant shifts detected in:\n",
      "  - hour (Wasserstein distance: 3.329)\n",
      "  - day_of_week (Wasserstein distance: 1.841)\n",
      "  - month (Wasserstein distance: 6.106)\n",
      "  - day_of_year (Wasserstein distance: 175.211)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n: Analyzing distribution shifts...\")\n",
    "analyzer = SpatioTemporalDistributionAnalyzer()\n",
    "spatial_stats, temporal_stats = analyzer.analyze(train_df, test_df)\n",
    "\n",
    "# Quick summary\n",
    "print(\"Significant shifts detected in:\")\n",
    "for feature, stats in temporal_stats.items():\n",
    "    if stats['ks_pvalue'] < 0.05:\n",
    "        print(f\"  - {feature} (Wasserstein distance: {stats['wasserstein_distance']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cc47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and transformed with feature_generator_1.pkl successfully.\n",
      "Loaded and transformed with feature_generator_2.pkl successfully.\n",
      "Loaded and transformed with feature_generator_3.pkl successfully.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop([\n",
    "    \"id\",\n",
    "    \"pollution_value\"], axis=1)\n",
    "y_train = train_df[\"pollution_value\"].copy()\n",
    "X_test = test_df.drop(\"id\", axis=1).copy()\n",
    "test_ids = test_df[\"id\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374db58-86e4-4197-99af-d70b44b51fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PHASE 2: ENHANCED CV PIPELINE WITH FULL FEATURE ENGINEERING\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from tabularaml.generate.features import FeatureGenerator\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def competition_metric(rmse: float) -> float:\n",
    "    \"\"\"Competition metric: exp(-RMSE / 100)\"\"\"\n",
    "    return np.exp(-rmse / 100)\n",
    "\n",
    "def load_and_apply_feature_generators(X_train_fold, X_val_fold, X_test_fold, model_dir):\n",
    "    \"\"\"\n",
    "    Load feature generators from directory and apply them sequentially.\n",
    "    Apply fit_transform on train, transform on val and test.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(model_dir):\n",
    "        return X_train_fold, X_val_fold, X_test_fold\n",
    "    \n",
    "    # Get all feature generator files and sort them\n",
    "    fg_files = [f for f in os.listdir(model_dir) if re.match(r\"feature_generator_\\d+\\.pkl\", f)]\n",
    "    fg_files = sorted(fg_files, key=lambda x: int(re.search(r\"\\d+\", x).group()))\n",
    "    \n",
    "    if not fg_files:\n",
    "        return X_train_fold, X_val_fold, X_test_fold\n",
    "    \n",
    "    for fg_file in fg_files:\n",
    "        try:\n",
    "            fg_path = os.path.join(model_dir, fg_file)\n",
    "            fg = FeatureGenerator.load(fg_path)\n",
    "            X_train_fold = fg.fit_transform(X_train_fold)\n",
    "            X_val_fold = fg.transform(X_val_fold)\n",
    "            X_test_fold = fg.transform(X_test_fold)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {fg_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return X_train_fold, X_val_fold, X_test_fold\n",
    "\n",
    "def enhanced_cv_pipeline(X_train, y_train, X_test, temporal_stats, model_dir=\"model_spatiotemporal\"):\n",
    "    \"\"\"\n",
    "    Enhanced CV pipeline with full feature engineering inside CV loops.\n",
    "    Order: AdvancedSpatioTemporalFeatures FIRST, then AFE pickles.\n",
    "    \"\"\"\n",
    "    print(\"=== ENHANCED CV PIPELINE ===\")\n",
    "    \n",
    "    # Setup CV splitter with optimized parameters\n",
    "    cv = SpatioTemporalCV(\n",
    "        n_splits=5,\n",
    "        test_spatial_coords=X_test[['latitude', 'longitude']].values,\n",
    "        test_temporal_features=X_test[['hour', 'month', 'day_of_week', 'day_of_year']],\n",
    "        spatial_weight=0.3,  # Emphasize temporal matching for January scarcity\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Domain adaptation for January weighting\n",
    "    domain_adapter = TemporalDomainAdaptation()\n",
    "    domain_adapter.fit(X_train, X_test)\n",
    "    sample_weights = domain_adapter.get_weights()\n",
    "    \n",
    "    # Boost January samples more aggressively\n",
    "    january_mask = X_train['month'] == 1\n",
    "    january_boost = 2.5  # Strong boost for January samples\n",
    "    sample_weights[january_mask] *= january_boost\n",
    "    sample_weights = np.clip(sample_weights, 0.1, 15.0)  # Clip to reasonable range\n",
    "    \n",
    "    print(f\"January samples: {january_mask.sum()}, Average January weight: {sample_weights[january_mask].mean():.2f}\")\n",
    "    \n",
    "    cv_scores = []\n",
    "    january_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        print(f\"Fold {fold + 1}/5...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold = X_train.iloc[train_idx].copy()\n",
    "        X_val_fold = X_train.iloc[val_idx].copy()\n",
    "        X_test_fold = X_test.copy()\n",
    "        y_train_fold = y_train.iloc[train_idx]\n",
    "        y_val_fold = y_train.iloc[val_idx]\n",
    "        \n",
    "        # STEP 1: Apply AdvancedSpatioTemporalFeatures FIRST\n",
    "        fe_full = AdvancedSpatioTemporalFeatures(\n",
    "            row_only=False,  \n",
    "            n_spatial_clusters=20,\n",
    "            n_temporal_clusters=10,\n",
    "            january_bridge_features=True,\n",
    "            test_distribution=temporal_stats,\n",
    "            use_distribution_matching=True\n",
    "        )\n",
    "        \n",
    "        X_train_enhanced = fe_full.fit_transform(X_train_fold, y_train_fold)\n",
    "        X_val_enhanced = fe_full.transform(X_val_fold)\n",
    "        X_test_enhanced = fe_full.transform(X_test_fold)\n",
    "        \n",
    "        # STEP 2: Apply AFE feature generators SECOND\n",
    "        X_train_enhanced, X_val_enhanced, X_test_enhanced = load_and_apply_feature_generators(\n",
    "            X_train_enhanced, X_val_enhanced, X_test_enhanced, model_dir\n",
    "        )\n",
    "        \n",
    "        # Handle NaNs using train fold statistics only\n",
    "        train_means = X_train_enhanced.mean()\n",
    "        X_train_enhanced = X_train_enhanced.fillna(train_means)\n",
    "        X_val_enhanced = X_val_enhanced.fillna(train_means)\n",
    "        \n",
    "        # Scale using train fold statistics\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_enhanced)\n",
    "        X_val_scaled = scaler.transform(X_val_enhanced)\n",
    "        \n",
    "        # Get weights for this fold\n",
    "        weights_train = sample_weights[train_idx]\n",
    "        \n",
    "        # Train XGBoost with early stopping in constructor\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=1.0,\n",
    "            reg_lambda=1.0,\n",
    "            min_child_weight=3,\n",
    "            early_stopping_rounds=50,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_scaled, y_train_fold,\n",
    "            sample_weight=weights_train,\n",
    "            eval_set=[(X_val_scaled, y_val_fold)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        val_pred = model.predict(X_val_scaled)\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_val_fold, val_pred))\n",
    "        cv_scores.append(fold_rmse)\n",
    "        \n",
    "        # Track January performance if any January samples in validation\n",
    "        january_val_mask = X_train.iloc[val_idx]['month'] == 1\n",
    "        if january_val_mask.sum() > 0:\n",
    "            january_rmse = np.sqrt(mean_squared_error(\n",
    "                y_val_fold[january_val_mask], \n",
    "                val_pred[january_val_mask]\n",
    "            ))\n",
    "            january_scores.append(january_rmse)\n",
    "    \n",
    "    # Results\n",
    "    overall_cv_score = np.mean(cv_scores)\n",
    "    january_cv_score = np.mean(january_scores) if january_scores else overall_cv_score\n",
    "    \n",
    "    print(f\"Overall CV RMSE: {overall_cv_score:.4f}\")\n",
    "    print(f\"January CV RMSE: {january_cv_score:.4f}\")\n",
    "    print(f\"Competition Score: {competition_metric(overall_cv_score):.6f}\")\n",
    "    \n",
    "    return {\n",
    "        'cv_scores': cv_scores,\n",
    "        'overall_cv_score': overall_cv_score,\n",
    "        'january_cv_score': january_cv_score,\n",
    "        'sample_weights': sample_weights,\n",
    "        'feature_engineering': fe_full,\n",
    "        'competition_score': competition_metric(overall_cv_score)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e17c0-57b8-466c-a7c1-24404ecfa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PHASE 3: ADVANCED HYPERPARAMETER OPTIMIZATION WITH OPTUNA\n",
    "# ==============================================================================\n",
    "\n",
    "def hyperparameter_optimization(X_train, y_train, X_test, temporal_stats, model_dir=\"model_spatiotemporal\", \n",
    "                               n_trials=100, timeout=7200, study_path=\"optuna_study_spatiotemporal.db\"):\n",
    "    \"\"\"\n",
    "    Advanced hyperparameter optimization with January-specific parameters.\n",
    "    Optimizes competition score: exp(-RMSE/100) (maximize)\n",
    "    \n",
    "    Args:\n",
    "        study_path: Path to SQLite database for persistent storage (default: \"optuna_study_spatiotemporal.db\")\n",
    "    \"\"\"\n",
    "    print(\"=== HYPERPARAMETER OPTIMIZATION ===\")\n",
    "    \n",
    "    # Setup CV\n",
    "    cv = SpatioTemporalCV(\n",
    "        n_splits=5,\n",
    "        test_spatial_coords=X_test[['latitude', 'longitude']].values,\n",
    "        test_temporal_features=X_test[['hour', 'month', 'day_of_week', 'day_of_year']],\n",
    "        spatial_weight=0.3,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Domain adaptation base weights\n",
    "    domain_adapter = TemporalDomainAdaptation()\n",
    "    domain_adapter.fit(X_train, X_test)\n",
    "    base_sample_weights = domain_adapter.get_weights()\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters including January-specific ones\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 2500),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'subsample': trial.suggest_float('subsample', 0.40, 0.95),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.40, 0.95),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 8.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 8.0, log=True),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 12),\n",
    "            \n",
    "            # January-specific parameters\n",
    "            'january_weight_boost': trial.suggest_float('january_weight_boost', 1.5, 4.0),\n",
    "            'max_weight_clip': trial.suggest_float('max_weight_clip', 10.0, 20.0),\n",
    "            \n",
    "            # Let Optuna suggest clustering parameters\n",
    "            'n_spatial_clusters': trial.suggest_int('n_spatial_clusters', 15, 35),\n",
    "            'n_temporal_clusters': trial.suggest_int('n_temporal_clusters', 8, 18),\n",
    "        }\n",
    "        \n",
    "        # Cross-validation\n",
    "        scores = []\n",
    "        january_scores = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "            # Prepare fold data\n",
    "            X_train_fold = X_train.iloc[train_idx].copy()\n",
    "            X_val_fold = X_train.iloc[val_idx].copy()\n",
    "            X_test_fold = X_test.copy()\n",
    "            y_train_fold = y_train.iloc[train_idx]\n",
    "            y_val_fold = y_train.iloc[val_idx]\n",
    "            \n",
    "            # STEP 1: Apply AdvancedSpatioTemporalFeatures FIRST\n",
    "            fe_trial = AdvancedSpatioTemporalFeatures(\n",
    "                row_only=False,\n",
    "                n_spatial_clusters=params['n_spatial_clusters'],\n",
    "                n_temporal_clusters=params['n_temporal_clusters'],\n",
    "                january_bridge_features=True,\n",
    "                test_distribution=temporal_stats,\n",
    "                use_distribution_matching=True\n",
    "            )\n",
    "            \n",
    "            X_train_enhanced = fe_trial.fit_transform(X_train_fold, y_train_fold)\n",
    "            X_val_enhanced = fe_trial.transform(X_val_fold)\n",
    "            X_test_enhanced = fe_trial.transform(X_test_fold)\n",
    "            \n",
    "            # STEP 2: Apply AFE pickles SECOND\n",
    "            X_train_enhanced, X_val_enhanced, X_test_enhanced = load_and_apply_feature_generators(\n",
    "                X_train_enhanced, X_val_enhanced, X_test_enhanced, model_dir\n",
    "            )\n",
    "            \n",
    "            # Handle NaNs\n",
    "            train_means = X_train_enhanced.mean()\n",
    "            X_train_enhanced = X_train_enhanced.fillna(train_means)\n",
    "            X_val_enhanced = X_val_enhanced.fillna(train_means)\n",
    "            \n",
    "            # Scale\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train_enhanced)\n",
    "            X_val_scaled = scaler.transform(X_val_enhanced)\n",
    "            \n",
    "            # Prepare weights with trial-specific January boosting\n",
    "            weights_optimized = base_sample_weights[train_idx].copy()\n",
    "            january_train_mask = X_train.iloc[train_idx]['month'] == 1\n",
    "            weights_optimized[january_train_mask] *= params['january_weight_boost']\n",
    "            weights_optimized = np.clip(weights_optimized, 0.1, params['max_weight_clip'])\n",
    "            \n",
    "            # Train model\n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=params['n_estimators'],\n",
    "                learning_rate=params['learning_rate'],\n",
    "                max_depth=params['max_depth'],\n",
    "                subsample=params['subsample'],\n",
    "                colsample_bytree=params['colsample_bytree'],\n",
    "                reg_alpha=params['reg_alpha'],\n",
    "                reg_lambda=params['reg_lambda'],\n",
    "                min_child_weight=params['min_child_weight'],\n",
    "                early_stopping_rounds=50,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                X_train_scaled, y_train_fold, \n",
    "                sample_weight=weights_optimized,\n",
    "                eval_set=[(X_val_scaled, y_val_fold)],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Evaluate\n",
    "            val_pred = model.predict(X_val_scaled)\n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val_fold, val_pred))\n",
    "            scores.append(fold_rmse)\n",
    "            \n",
    "            # Track January performance\n",
    "            january_val_mask = X_train.iloc[val_idx]['month'] == 1\n",
    "            if january_val_mask.sum() > 0:\n",
    "                january_rmse = np.sqrt(mean_squared_error(\n",
    "                    y_val_fold[january_val_mask], \n",
    "                    val_pred[january_val_mask]\n",
    "                ))\n",
    "                january_scores.append(january_rmse)\n",
    "        \n",
    "        # Calculate score components\n",
    "        overall_rmse = np.mean(scores)\n",
    "        january_rmse = np.mean(january_scores) if january_scores else overall_rmse\n",
    "        \n",
    "        # Combined RMSE weighted towards January\n",
    "        combined_rmse = 0.4 * overall_rmse + 0.6 * january_rmse\n",
    "        \n",
    "        # Convert to competition scores\n",
    "        overall_competition_score = competition_metric(overall_rmse)\n",
    "        january_competition_score = competition_metric(january_rmse)\n",
    "        combined_competition_score = competition_metric(combined_rmse)\n",
    "        \n",
    "        # Store detailed results in trial user attributes for logging\n",
    "        trial.set_user_attr(\"overall_rmse\", overall_rmse)\n",
    "        trial.set_user_attr(\"january_rmse\", january_rmse)\n",
    "        trial.set_user_attr(\"combined_rmse\", combined_rmse)\n",
    "        trial.set_user_attr(\"overall_comp_score\", overall_competition_score)\n",
    "        trial.set_user_attr(\"january_comp_score\", january_competition_score)\n",
    "        trial.set_user_attr(\"combined_comp_score\", combined_competition_score)\n",
    "        trial.set_user_attr(\"january_samples_in_val\", sum(len(january_scores) for _ in range(len(january_scores))))\n",
    "        \n",
    "        # Print trial results\n",
    "        print(f\"Trial {trial.number:3d}: Overall RMSE={overall_rmse:.4f} (Score={overall_competition_score:.6f}), \"\n",
    "              f\"Jan RMSE={january_rmse:.4f} (Score={january_competition_score:.6f}), \"\n",
    "              f\"Combined RMSE={combined_rmse:.4f} (Score={combined_competition_score:.6f})\")\n",
    "        \n",
    "        # Return negative competition score for minimization\n",
    "        return -combined_competition_score\n",
    "    \n",
    "    # Setup persistent storage\n",
    "    study_name = \"spatiotemporal_competition_optimization\"\n",
    "    storage_url = f\"sqlite:///{study_path}\"\n",
    "    \n",
    "    # Calculate startup trials (10% of total)\n",
    "    n_startup_trials = max(1, int(n_trials * 0.1))\n",
    "    \n",
    "    # Create or load study with TPE sampler - PROPER RESUME IMPLEMENTATION\n",
    "    sampler = optuna.samplers.TPESampler(\n",
    "        multivariate=True,\n",
    "        n_startup_trials=n_startup_trials,  # Fixed: was n_warmup_steps\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Use load_if_exists=True for proper resume capability\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_url,\n",
    "        direction='minimize',  # Minimize negative competition score = maximize competition score\n",
    "        sampler=sampler,\n",
    "        load_if_exists=True  # This enables resume functionality\n",
    "    )\n",
    "    \n",
    "    # Check existing trials and calculate remaining\n",
    "    existing_trials = len(study.trials)\n",
    "    \n",
    "    if existing_trials > 0:\n",
    "        print(f\"üìÅ Resumed existing study with {existing_trials} completed trials. Will run another {n_trials} trials\")\n",
    "    else:\n",
    "        print(f\"üÜï Created new study, will run {n_trials} trials\")\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Using TPE sampler: multivariate=True, startup_trials={n_startup_trials}\")\n",
    "    print(f\"üíæ Storage: {storage_url}\")\n",
    "    \n",
    "    # Only run if we have remaining trials\n",
    "    print(f\"üöÄ Starting optimization...\")\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout)\n",
    "\n",
    "    # Calculate final metrics\n",
    "    best_negative_score = study.best_value\n",
    "    best_competition_score = -best_negative_score\n",
    "    \n",
    "    # Get detailed results from best trial\n",
    "    best_trial = study.best_trial\n",
    "    best_overall_rmse = best_trial.user_attrs[\"overall_rmse\"]\n",
    "    best_january_rmse = best_trial.user_attrs[\"january_rmse\"]\n",
    "    best_combined_rmse = best_trial.user_attrs[\"combined_rmse\"]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üèÜ OPTIMIZATION COMPLETE ({len(study.trials)} total trials)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìä Best Results (Trial #{best_trial.number}):\")\n",
    "    print(f\"   Overall RMSE: {best_overall_rmse:.4f} ‚Üí Score: {competition_metric(best_overall_rmse):.6f}\")\n",
    "    print(f\"   January RMSE: {best_january_rmse:.4f} ‚Üí Score: {competition_metric(best_january_rmse):.6f}\")\n",
    "    print(f\"   Combined RMSE: {best_combined_rmse:.4f} ‚Üí Score: {best_competition_score:.6f}\")\n",
    "    print(f\"\\nüéØ Best Parameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # Study statistics\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    if len(completed_trials) > 1:\n",
    "        scores = [-t.value for t in completed_trials]\n",
    "        print(f\"\\nüìà Study Statistics:\")\n",
    "        print(f\"   Best Score: {max(scores):.6f}\")\n",
    "        print(f\"   Mean Score: {np.mean(scores):.6f}\")\n",
    "        print(f\"   Std Score: {np.std(scores):.6f}\")\n",
    "        print(f\"   Improvement: {max(scores) - min(scores):.6f}\")\n",
    "    \n",
    "    return study.best_params, best_combined_rmse, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e303af-cb07-44dd-a84e-32035c4913c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PHASE 4: ENSEMBLE STRATEGY AND FINAL MODEL\n",
    "# ==============================================================================\n",
    "\n",
    "def create_ensemble_variants(best_params, X_train, y_train, X_test, temporal_stats, model_dir=\"model_spatiotemporal\"):\n",
    "    \"\"\"\n",
    "    Create multiple model variants for ensemble diversity.\n",
    "    \"\"\"\n",
    "    print(\"=== CREATING ENSEMBLE VARIANTS ===\")\n",
    "    \n",
    "    # Base optimized parameters\n",
    "    base_params = {k: v for k, v in best_params.items() \n",
    "                   if k not in ['january_weight_boost', 'max_weight_clip', 'n_spatial_clusters', 'n_temporal_clusters']}\n",
    "    \n",
    "    # Variant 1: Conservative (higher regularization)\n",
    "    conservative_params = base_params.copy()\n",
    "    conservative_params.update({\n",
    "        'reg_alpha': base_params['reg_alpha'] * 1.3,\n",
    "        'reg_lambda': base_params['reg_lambda'] * 1.3,\n",
    "        'learning_rate': base_params['learning_rate'] * 0.8,\n",
    "        'january_weight_boost': best_params['january_weight_boost'] * 0.8\n",
    "    })\n",
    "    \n",
    "    # Variant 2: Aggressive (lower regularization, higher learning rate)\n",
    "    aggressive_params = base_params.copy()\n",
    "    aggressive_params.update({\n",
    "        'reg_alpha': base_params['reg_alpha'] * 0.7,\n",
    "        'reg_lambda': base_params['reg_lambda'] * 0.7,\n",
    "        'learning_rate': min(0.12, base_params['learning_rate'] * 1.2),\n",
    "        'january_weight_boost': best_params['january_weight_boost'] * 1.1\n",
    "    })\n",
    "    \n",
    "    # Variant 3: January-focused (extra January emphasis)\n",
    "    january_params = base_params.copy()\n",
    "    january_params.update({\n",
    "        'january_weight_boost': best_params['january_weight_boost'] * 1.4,\n",
    "        'max_depth': max(4, best_params['max_depth'] - 1),\n",
    "        'min_child_weight': best_params['min_child_weight'] + 1\n",
    "    })\n",
    "    \n",
    "    ensemble_variants = {\n",
    "        'conservative': conservative_params,\n",
    "        'aggressive': aggressive_params, \n",
    "        'january_focused': january_params,\n",
    "        'optimized': base_params\n",
    "    }\n",
    "    \n",
    "    for name, params in ensemble_variants.items():\n",
    "        # Add back non-model parameters\n",
    "        params['january_weight_boost'] = params.get('january_weight_boost', best_params['january_weight_boost'])\n",
    "        params['max_weight_clip'] = best_params['max_weight_clip']\n",
    "        params['n_spatial_clusters'] = best_params['n_spatial_clusters']\n",
    "        params['n_temporal_clusters'] = best_params['n_temporal_clusters']\n",
    "    \n",
    "    return ensemble_variants\n",
    "\n",
    "def train_final_ensemble(ensemble_variants, X_train, y_train, X_test, temporal_stats, model_dir=\"model_spatiotemporal\"):\n",
    "    \"\"\"\n",
    "    Train final ensemble with all variants and create submission.\n",
    "    Order: AdvancedSpatioTemporalFeatures FIRST, then AFE pickles.\n",
    "    \"\"\"\n",
    "    print(\"=== TRAINING FINAL ENSEMBLE ===\")\n",
    "    \n",
    "    # Domain adaptation weights\n",
    "    domain_adapter = TemporalDomainAdaptation()\n",
    "    domain_adapter.fit(X_train, X_test)\n",
    "    base_weights = domain_adapter.get_weights()\n",
    "    \n",
    "    ensemble_predictions = {}\n",
    "    \n",
    "    for variant_name, params in ensemble_variants.items():\n",
    "        print(f\"Training {variant_name} variant...\")\n",
    "        \n",
    "        # Prepare full training data\n",
    "        X_train_full = X_train.copy()\n",
    "        X_test_full = X_test.copy()\n",
    "        \n",
    "        # STEP 1: Apply AdvancedSpatioTemporalFeatures FIRST\n",
    "        fe_final = AdvancedSpatioTemporalFeatures(\n",
    "            row_only=False,\n",
    "            n_spatial_clusters=params['n_spatial_clusters'],\n",
    "            n_temporal_clusters=params['n_temporal_clusters'],\n",
    "            january_bridge_features=True,\n",
    "            test_distribution=temporal_stats,\n",
    "            use_distribution_matching=True\n",
    "        )\n",
    "        \n",
    "        X_train_enhanced = fe_final.fit_transform(X_train_full, y_train)\n",
    "        X_test_enhanced = fe_final.transform(X_test_full)\n",
    "        \n",
    "        # STEP 2: Apply AFE feature generators SECOND\n",
    "        X_train_enhanced, _, X_test_enhanced = load_and_apply_feature_generators(\n",
    "            X_train_enhanced, X_train_enhanced.iloc[:0], X_test_enhanced, model_dir\n",
    "        )\n",
    "        \n",
    "        # Handle NaNs\n",
    "        train_means = X_train_enhanced.mean()\n",
    "        X_train_enhanced = X_train_enhanced.fillna(train_means)\n",
    "        X_test_enhanced = X_test_enhanced.fillna(train_means)\n",
    "        \n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_enhanced)\n",
    "        X_test_scaled = scaler.transform(X_test_enhanced)\n",
    "        \n",
    "        # Prepare sample weights\n",
    "        sample_weights = base_weights.copy()\n",
    "        january_mask = X_train['month'] == 1\n",
    "        sample_weights[january_mask] *= params['january_weight_boost']\n",
    "        sample_weights = np.clip(sample_weights, 0.1, params['max_weight_clip'])\n",
    "        \n",
    "        # Train final model - REMOVE early_stopping_rounds for final training\n",
    "        model_params = {k: v for k, v in params.items() \n",
    "                       if k not in ['january_weight_boost', 'max_weight_clip', 'n_spatial_clusters', 'n_temporal_clusters']}\n",
    "        # Remove early_stopping_rounds for final model (no validation set)\n",
    "        model_params.pop('early_stopping_rounds', None)\n",
    "        \n",
    "        final_model = xgb.XGBRegressor(**model_params, random_state=42)\n",
    "        final_model.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = final_model.predict(X_test_scaled)\n",
    "        ensemble_predictions[variant_name] = predictions\n",
    "    \n",
    "    return ensemble_predictions\n",
    "\n",
    "def create_final_submission(ensemble_predictions, X_test, test_ids):\n",
    "    \"\"\"\n",
    "    Create final submission with weighted ensemble.\n",
    "    \"\"\"\n",
    "    print(\"=== CREATING FINAL SUBMISSION ===\")\n",
    "    \n",
    "    # Ensemble weights\n",
    "    ensemble_weights = {\n",
    "        'conservative': 0.2,\n",
    "        'aggressive': 0.2,\n",
    "        'january_focused': 0.35,  # Higher weight for January-focused variant\n",
    "        'optimized': 0.25\n",
    "    }\n",
    "    \n",
    "    # Create weighted ensemble\n",
    "    final_predictions = np.zeros(len(X_test))\n",
    "    for variant_name, predictions in ensemble_predictions.items():\n",
    "        weight = ensemble_weights[variant_name]\n",
    "        final_predictions += weight * predictions\n",
    "    \n",
    "    # Apply January-specific post-processing\n",
    "    january_test_mask = X_test['month'] == 1\n",
    "    if january_test_mask.sum() > 0:\n",
    "        high_latitude_january = january_test_mask & (X_test['latitude'] > 45)\n",
    "        if high_latitude_january.sum() > 0:\n",
    "            final_predictions[high_latitude_january] *= 1.05\n",
    "    \n",
    "    # Post-process predictions\n",
    "    final_predictions = np.maximum(final_predictions, 0)\n",
    "    final_predictions = np.minimum(final_predictions, 200)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'pollution_value': final_predictions\n",
    "    })\n",
    "    \n",
    "    print(f\"Final predictions: Range=[{final_predictions.min():.2f}, {final_predictions.max():.2f}], Mean={final_predictions.mean():.2f}\")\n",
    "    \n",
    "    # January-specific stats\n",
    "    if january_test_mask.sum() > 0:\n",
    "        january_preds = final_predictions[january_test_mask]\n",
    "        print(f\"January: Mean={january_preds.mean():.2f}, Std={january_preds.std():.2f}\")\n",
    "    \n",
    "    return submission, final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfcfb3-5777-4a47-9a90-199b97d9c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# COMPLETE PIPELINE EXECUTION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üöÄ STARTING COMPLETE COMPETITION PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Run Enhanced CV Pipeline\n",
    "print(\"\\nüìä STEP 1: Enhanced CV Pipeline\")\n",
    "cv_results = enhanced_cv_pipeline(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    temporal_stats=temporal_stats,\n",
    "    model_dir=DIR\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ CV Results: RMSE={cv_results['overall_cv_score']:.4f}, Competition Score={cv_results['competition_score']:.6f}\")\n",
    "\n",
    "# Step 2: Hyperparameter Optimization\n",
    "print(\"\\nüéØ STEP 2: Hyperparameter Optimization\")\n",
    "best_params, best_rmse, study = hyperparameter_optimization(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    temporal_stats=temporal_stats,\n",
    "    model_dir=DIR,\n",
    "    n_trials=1000,\n",
    "    timeout=3*3600 \n",
    ")\n",
    "\n",
    "best_competition_score = competition_metric(best_rmse)\n",
    "print(f\"‚úÖ Optimization complete: Competition Score={best_competition_score:.6f}\")\n",
    "\n",
    "# Step 3: Create Ensemble Variants\n",
    "print(\"\\nüé≠ STEP 3: Creating Ensemble Variants\")\n",
    "ensemble_variants = create_ensemble_variants(\n",
    "    best_params=best_params,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    temporal_stats=temporal_stats,\n",
    "    model_dir=DIR\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created {len(ensemble_variants)} ensemble variants\")\n",
    "\n",
    "# Step 4: Train Final Ensemble\n",
    "print(\"\\nüèÜ STEP 4: Training Final Ensemble\")\n",
    "ensemble_predictions = train_final_ensemble(\n",
    "    ensemble_variants=ensemble_variants,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    temporal_stats=temporal_stats,\n",
    "    model_dir=DIR\n",
    ")\n",
    "\n",
    "# Step 5: Create Final Submission\n",
    "print(\"\\nüìã STEP 5: Creating Final Submission\")\n",
    "final_submission, final_predictions = create_final_submission(\n",
    "    ensemble_predictions=ensemble_predictions,\n",
    "    X_test=X_test,\n",
    "    test_ids=test_ids\n",
    ")\n",
    "\n",
    "# Save submission with competition score in filename\n",
    "filename = f\"submission_enhanced_{best_competition_score:.6f}_rmse_{best_rmse:.4f}.csv\"\n",
    "final_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üèÖ Best Competition Score: {best_competition_score:.6f}\")\n",
    "print(f\"üìà Estimated RMSE: {best_rmse:.4f}\")\n",
    "print(f\"üìä January Performance: {cv_results['january_cv_score']:.4f}\")\n",
    "print(f\"üíæ Submission saved: {filename}\")\n",
    "print(f\"üóìÔ∏è January test samples: {(X_test['month'] == 1).sum()}\")\n",
    "\n",
    "# Save Optuna study for analysis\n",
    "study.trials_dataframe().to_csv(f\"optuna_trials_{best_competition_score:.6f}.csv\", index=False)\n",
    "print(f\"üíæ Optuna trials saved: optuna_trials_{best_competition_score:.6f}.csv\")\n",
    "\n",
    "print(\"\\n‚ú® Ready for submission! Expected strong performance on January-heavy test data! ‚ú®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191af8b-bb91-4bd4-8644-47845c74733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# ADVERSARIAL VALIDATION & SUBMISSION VARIANTS (OPTIONAL)\n",
    "# ==============================================================================\n",
    "\n",
    "def adversarial_validation_analysis(X_train, X_test, final_predictions):\n",
    "    \"\"\"\n",
    "    Identify train samples most similar to test distribution for robustness check.\n",
    "    \"\"\"\n",
    "    print(\"=== ADVERSARIAL VALIDATION ANALYSIS ===\")\n",
    "    \n",
    "    # Combine train and test for adversarial validation\n",
    "    X_combined = pd.concat([\n",
    "        X_train[['latitude', 'longitude', 'hour', 'day_of_week', 'month', 'day_of_year']],\n",
    "        X_test[['latitude', 'longitude', 'hour', 'day_of_week', 'month', 'day_of_year']]\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Create target: 0 for train, 1 for test\n",
    "    y_adversarial = np.concatenate([\n",
    "        np.zeros(len(X_train)),\n",
    "        np.ones(len(X_test))\n",
    "    ])\n",
    "    \n",
    "    # Train classifier to distinguish train vs test\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    adversarial_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    adversarial_model.fit(X_combined, y_adversarial)\n",
    "    \n",
    "    # Get prediction probabilities for train samples\n",
    "    train_test_probs = adversarial_model.predict_proba(X_combined[:len(X_train)])[:, 1]\n",
    "    \n",
    "    # Identify most test-like training samples\n",
    "    test_like_threshold = np.percentile(train_test_probs, 90)  # Top 10% most test-like\n",
    "    test_like_mask = train_test_probs > test_like_threshold\n",
    "    \n",
    "    print(f\"Found {test_like_mask.sum()} test-like training samples (top 10%)\")\n",
    "    print(f\"January samples in test-like: {X_train[test_like_mask]['month'].eq(1).sum()}\")\n",
    "    print(f\"Test-like sample score threshold: {test_like_threshold:.3f}\")\n",
    "    \n",
    "    # Analyze prediction consistency\n",
    "    january_test_preds = final_predictions[X_test['month'] == 1]\n",
    "    all_test_preds = final_predictions\n",
    "    \n",
    "    print(f\"\\nPrediction Analysis:\")\n",
    "    print(f\"January test predictions - Mean: {january_test_preds.mean():.2f}, Std: {january_test_preds.std():.2f}\")\n",
    "    print(f\"All test predictions - Mean: {all_test_preds.mean():.2f}, Std: {all_test_preds.std():.2f}\")\n",
    "    \n",
    "    return test_like_mask, train_test_probs\n",
    "\n",
    "def create_submission_variants(ensemble_predictions, X_test, test_ids):\n",
    "    \"\"\"\n",
    "    Create multiple submission variants for robustness.\n",
    "    \"\"\"\n",
    "    print(\"=== CREATING SUBMISSION VARIANTS ===\")\n",
    "    \n",
    "    submissions = {}\n",
    "    \n",
    "    # Variant 1: Conservative ensemble (equal weights)\n",
    "    conservative_preds = np.mean([pred for pred in ensemble_predictions.values()], axis=0)\n",
    "    conservative_preds = np.maximum(conservative_preds, 0)\n",
    "    submissions['conservative'] = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'pollution_value': conservative_preds\n",
    "    })\n",
    "    \n",
    "    # Variant 2: January-focused (boost January-focused model)\n",
    "    january_focused_preds = (\n",
    "        0.15 * ensemble_predictions['conservative'] +\n",
    "        0.15 * ensemble_predictions['aggressive'] +\n",
    "        0.50 * ensemble_predictions['january_focused'] +  # Heavy January weight\n",
    "        0.20 * ensemble_predictions['optimized']\n",
    "    )\n",
    "    january_focused_preds = np.maximum(january_focused_preds, 0)\n",
    "    submissions['january_heavy'] = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'pollution_value': january_focused_preds\n",
    "    })\n",
    "    \n",
    "    # Variant 3: Median ensemble (robust to outliers)\n",
    "    median_preds = np.median([pred for pred in ensemble_predictions.values()], axis=0)\n",
    "    median_preds = np.maximum(median_preds, 0)\n",
    "    submissions['median'] = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'pollution_value': median_preds\n",
    "    })\n",
    "    \n",
    "    # Variant 4: Optimized single model\n",
    "    optimized_preds = ensemble_predictions['optimized']\n",
    "    optimized_preds = np.maximum(optimized_preds, 0)\n",
    "    submissions['single_optimized'] = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'pollution_value': optimized_preds\n",
    "    })\n",
    "    \n",
    "    # Save all variants\n",
    "    for name, submission in submissions.items():\n",
    "        filename = f\"submission_variant_{name}.csv\"\n",
    "        submission.to_csv(filename, index=False)\n",
    "        \n",
    "        # Stats\n",
    "        preds = submission['pollution_value'].values\n",
    "        january_mask = X_test['month'] == 1\n",
    "        january_preds = preds[january_mask]\n",
    "        \n",
    "        print(f\"{name:15s}: Mean={preds.mean():.2f}, Jan_Mean={january_preds.mean():.2f}, \"\n",
    "              f\"Range=[{preds.min():.1f}, {preds.max():.1f}] -> {filename}\")\n",
    "    \n",
    "    return submissions\n",
    "\n",
    "# Run adversarial validation\n",
    "if 'final_predictions' in locals() and 'X_train' in locals():\n",
    "    test_like_mask, adversarial_probs = adversarial_validation_analysis(\n",
    "        X_train, X_test, final_predictions\n",
    "    )\n",
    "    \n",
    "    # Create submission variants\n",
    "    if 'ensemble_predictions' in locals():\n",
    "        submission_variants = create_submission_variants(\n",
    "            ensemble_predictions, X_test, test_ids\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n‚úÖ Created {len(submission_variants)} submission variants\")\n",
    "        print(\"üìã Files saved:\")\n",
    "        for variant in submission_variants.keys():\n",
    "            print(f\"  - submission_variant_{variant}.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping adversarial validation - run main pipeline first\")\n",
    "\n",
    "print(\"\\nüéØ RECOMMENDATION:\")\n",
    "print(\"1. Try 'january_heavy' variant if LB shows January struggles\")\n",
    "print(\"2. Use 'conservative' variant for safety\")\n",
    "print(\"3. Compare 'median' vs main ensemble for robustness\")\n",
    "print(\"4. Monitor 'single_optimized' to verify ensemble value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
